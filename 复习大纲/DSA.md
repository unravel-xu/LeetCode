# 1 绪论
## 1-C 渐进复杂度
- $T(n) = O(f(n)) \iff \exists c>0 \quad s.t. \ T(n)\leq c\cdot f(n) \ \forall n\gg 2$（渐近上界）
- $T(n) = o(f(n)) \iff \exists c>0 \quad s.t. \ T(n)< c\cdot f(n) \ \forall n\gg 2$（严格上界）
- $T(n) = \Omega(f(n)) \iff \exists c>0 \quad s.t. \ T(n)\geq c\cdot f(n) \ \forall n\gg 2$（渐近下界）
- $T(n) = \omega(f(n)) \iff \exists c>0 \quad s.t. \ T(n)>c\cdot f(n) \ \forall n\gg 2$（严格下界）
- $T(n) = \Theta(f(n)) \iff \exists c_{1}>c_{2}>0 \quad s.t. \ c_{1}\cdot f(n)>T(n)>c_{2}\cdot f(n) \ \forall n\gg 2$（确界）
O(1)：常数次循环、不可达分支、不可能成立的递归调用条件
$\log^{*}n$：连续取对数使值 $\leq 1$ 的次数
例：$\log_{2}^*16 = 3 \ \to (\log_{2}(\log_{2}(\log_{2}(16)))=\log_{2}(\log_{2}(4))=\log_{2}2=1)$
## 1-D 复杂度分析
- 幂方级数：$T(n)=\Sigma_{k=0}^n k^d=O(n^{d+1})$    比幂次高出一阶
- 几何级数：$T_{a}(n)=\Sigma_{k=0}^n a^k = O(a^n) \, \ 1<a$ 与末项同阶
- 调和级数：$h(n)=\Sigma_{k=1}^n \frac{1}{k} = \ln n+\gamma+O\left( \frac{1}{2n} \right) =\Theta(log \ n)$
- 对数级数：$\Sigma_{k=1}^n\ln k=\ln n! =\Theta(n\cdot \log n)$
- 组合：$\Sigma_{k=1}^nk\cdot \log k=O(n^2\log n)$
	  $\Sigma_{k=1}^nk\cdot 2^k=O(n\cdot 2^n)$
算法正确性的证明（以冒泡排序为例）：
1. 不变性：经过 k 轮扫描交换后，最大的 k 个元素必然就位
2. 单调性：经过 k 轮扫描交换后，问题规模缩减至 n-k
3. 正确性：经过至多 n 趟扫描后，算法必然终止，且能给出正确解答
【习题 1-5】随着输入规模的扩大，同一算法所需的计算时间可能上下波动
![](Images/Pasted%20image%2020241125151756.png)
- 封底估计：粗略估计
【习题 1-11】若 $f(n) = O(n^2),\ g(n)=O(n)$，判断以下结论是否正确：
1. $\frac{f(n)}{g(n)} = O(n)$
❌，取 $f(n) = nlogn<n^2,\ g(n)=1<n$，则 $\frac{f(n)}{g(n)}=nlogn>n$
2. $g(n)=O(f(n))$
❌，取 $f(n) = logn<n^2,\ g(n)=n>f(n)$
【习题 1-32】分析以下函数 F(n)，确定其渐进复杂度的上界
```c
void F(int n){
	for(int i=1; i<n; i++)
	for(int j=0; j<n; j+=i);
}
```
循环累计迭代次数：$\Sigma_{i=1}^{n-1} \frac{n}{i} = O(nlogn)$
```c
void F(int n){
	for(int i=0, j=0; i<n; i+=j, j++);
}
```
每经过一步迭代，i 增加 j，j 增加 1
![](Images/Pasted%20image%2020241125164657.png)
经过 k 次迭代后，$i = \frac{k(k-1)}{2}<n$，时间复杂度为 $O(\sqrt{n})$
```c
void F(int n){
	for(int i=1, r=1; i<n; i<<=r, r<<=1);
}
```
每经过一步迭代，$i$ 递增为 $i\cdot2^r$，$r$ 递增为 $2\cdot r$
![](Images/Pasted%20image%2020241125165225.png)
$i = 2^{\Sigma_{t=0}^{k-1}2^t} = 2^{2^k-1}<n$，时间复杂度为 $O(loglogn)$
```c
void F(int n){
	for(int i=1; i<n; i=1<<i);
}
```
每经过一步迭代，$i$ 递增为 $2^i$，$2^{2^{2^{...}}}<n$，时间复杂度为$O(\log^{*}n)$
```c
int F(int n){
	return (n>0) ? G(G(n-1)) : 0;
}
int G(int n){
	return (n>0) ? G(n-1) + 2*n-1 : 0;
}
```
先分析 $G(n) = \Sigma \ 1+3+5+...+2n-1=n^2$，运行时间 $g(n) = O(n)$
$F()$ 并非递归函数，其本身只消耗 $O(1)$ 时间，但 $F(n)$ 会启动 $G()$ 的<font color="#ff0000">两次递归</font>，入口参数分别为 $n-1$ 和 $(n-1)^2$，总体时间复杂度：
$$\begin{align}
f(n) & = O(1) + g(n-1) + g((n-1)^2) \\
& = O(1) + O(n-1) + O((n-1)^2) \\
& = O(n^2)
\end{align}
$$
```c
void F(int n){
	for(int i=1; i<n/G(i,0); i++);
}
int G(int n, int k){
	return (n<1) ? k : G(n-2*k-1, k+1);
}
```
先分析 $G(n)$，$G(n,0)\to G(n-1,1)\to G(n-4,2)\to G(n-9,3)...$
所以 $g(n) = O(\lceil\sqrt{n}\rceil)$，F()终止迭代时 $i\geq \frac{n}{\lceil\sqrt{i}\rceil}$，所以 $i=\Theta(n^{\frac{2}{3}})$
F()每轮运行时需要计算 $G(i,0)$，总体时间复杂度：
$$\begin{align}
f(n) & = g(1) + g(2) +...+ g(i_{\max}) \\
& = O(\sqrt{1}) + O(\sqrt{2}) + O(\sqrt{n^{\frac{2}{3}}}) \\
& = O(\int_{0}^{n^{\frac{2}{3}}} \sqrt{x} dx) \\
& = O(n)
\end{align}
$$
```c
int F(int n){
	return (n>0) ? G(2, F(n-1)) : 1;
}
int G(int n, int m){
	return (m>0) ? n + G(n, m-1) : 0;
}
```
$G(n,m) = n*m$，$F(n) = 2^n$，$g(n,m)=O(m)$
![|650](Images/Pasted%20image%2020241125180259.png)
$F(n)\to G(2, F(n-1))\to F(n-1)\to G(2, F(n-2))\to ...$
总体时间复杂度：$f(n)=f(n-1)+g(2,\ 2^{n-1}) = f(n-1)+O(2^{n-1})=O(2^n)$
```c
int F(int n){
	return (n>3) ? F(n>>1) + F(n>>2) : n;
}
```
$f(n) = f\left( \frac{n}{2} \right)+f\left( \frac{n}{4} \right) + 1$，令 $s(m) = f(2^m)$，$s(m) = s(m-1) + s(m-2) + 1$，再令 $t(m) = \frac{s(m)+1}{2}$
可得 $t(m) = t(m-1)+t(m-2)$ (Fibonacci)
所以 $t(m) = fib(m+1) = O(\Phi^m)$，$f(n) = O(n^{\log\Phi})$
```c
void F(int n){
	for(int i=n; 0<i ; i--){
	    if(!(rand()%i))
	        for(int j=0;j<n;j++);
	}
}
```
假定属于均匀随机分布，所以 rand()能整除变量 i 的概率为 $\frac{1}{i}$，变量 i 的内循环平均迭代 $\frac{n}{i}$ 步，总体时间复杂度：
$f(n) = \frac{n}{n} + \frac{n}{n-1} +...+ \frac{n}{1}=O(nlogn)$
## 1-E 递归与迭代
空间复杂度：除了输入本身所占空间外，所需另加的用于计算所必须的空间总量
递归实例的空间复杂度只和递归实例<font color="#d83931">树高</font>相关
递归实例的时间复杂度和递归实例总数相关
**主定理**：$T(n) = a\cdot T\left( \frac{n}{b} \right)+O(f(n))$
1. 若 $n^{\log_{b}a} > f(n)$ 则 $T(n)=\Theta (n^{\log_{b}a})$
2. 若 $f(n) > n^{\log_{b}a}$ 则 $T(n)=\Theta(f(n))$
3. 若 $f(n) = \Theta(n^{\log_{b}a}\cdot \log^k n)$，则 $T(n)=\Theta(n^{\log_{b}a}\cdot \log^{k+1}n)$  $\textcolor{red}{k\geq 0}$
		$\underbrace{A}_{n}\times \underbrace{B}_{n}$
$\times$	        	$\underbrace{C}_{n}\times \underbrace{D}_{n}$
——————————
$\underbrace{A}_{n}\times \underbrace{C}_{n}$
		$\underbrace{B}_{n}\times \underbrace{D}_{n}$
	$\underbrace{B}_{n}\times \underbrace{C}_{n}$
	$\underbrace{A}_{n}\times \underbrace{D}_{n}$
$B \times C + A \times D = A \times C + B \times D + (A-B) \times (D-C)$ 这样可以只算 3 个 $n \times n$ 乘法
[01-E3递归与迭代：总和最大区段](912%20DSA复习笔记.md#01-E3递归与迭代：总和最大区段)
## 1-F 动态规划
## 1-XA1 缓存
就地循环位移：考虑 cache，三次倒置 $O(3n)$ 最佳
![|500](Images/Pasted%20image%2020241125161857.png)
# 2 向量
## 2-B 可扩容向量

|        | 容量递增策略          | 容量加倍策略  |
| ------ | --------------- | ------- |
| 累计扩容时间 | $O(n^2)$        | $O(n)$  |
| 分摊扩容时间 | $O(n)$          | $O(1)$  |
| 空间利用率  | $\approx 100\%$ | $>50\%$ |
 - 平均分析：根据各种操作出现的概率分布，将对应成本加权平均
   割裂了操作之间的相关性和连贯性
 - 分摊分析：连续实施足够多次操作，所需总体成本分摊到单次操作
   更加精准的评判真实性能
## 2-C 无序向量
- 去重：从第二个元素开始，自前向后逐一在当前元素的前缀中寻找相同元素并删除
- 删除：若以自后向前的次序逐个前移后继元素，位置靠前的元素可能被位置靠后的元素覆盖造成数据丢失
## 2-D 有序向量
 - 去重：发现不同元素时，直接将其前移至前者右侧，最后截去尾部多余元素
 - 二分查找：
   1. 版本 A：分成【lo，mi）->(1 次比较) mid->(2 次比较)（mi，hi】->(2次比较)
   2. 版本 B：分成【lo，mi）【mi，hi），只有当区间长度缩短到 1 才终止，版本 A 只要找到等于 mid 就可以终止，最好(坏)情况下更坏(好)，整体性能趋于均衡
   3. 版本 C：相比于版本B 左边界取作 mi+1 而不是 mi，区间长度缩短到 0 才终止，返回的是不超过 e 的最大秩
- Fibonacci 查找：版本 A 的基础上，当 $n=fib(k)-1$ 取 $mi = fib(k-1)-1$
- 插值查找：猜测线性关系，$\frac {{mi-lo}} {hi-lo} \approx \frac{e-A[lo]}{A[hi]-A[lo]}$，平均：每经过一次比较，待查找区间宽度由 n 缩至 $\sqrt{n}$ 时间 $O(loglog\ n)$

插值查找：在字长意义上的折半查找
二分查找：在字长意义上的顺序查找
【习题 2-17】用向量存放一组字符串，依据字典序确定字符串之间的次序，若共有 <font color="#ff0000">n 个字符串</font>，二分查找的复杂度是否仍为 $O(\log n)$
>[!tip]-
> 与整数、字符之类的基本数据类型不同，字符串的长度并不确定，且无上限，字符串之间的比较不能继续视作基本操作

【习题 2-18】二分查找 binSearch()算法版本 A，针对独立均匀分布
二\[0, 2n\]内的整数目标，在固定的有序向量{ 1, 3, 5, ..., 2n - 1 }中查找。
a）若将平均的成功和失败查找长度分别记作 S 和 F，试证明：(S + 1)∙n = F∙(n + 1)
考查 binSearch() 算法对应的比较树。一般地，若向量的规模为 n，则对应的比较树应由 n 个内部节点（成功的返回）以及 n + 1 个叶节点（失败的返回）
![](Images/Pasted%20image%2020241125222343.png)
假设 n-1 个节点的向量中，失败情况<font color="#ff0000">X</font>所对应的查找长度为 d，则如图 n 个节点的向量中，X 对应成功查找长度为 d+2(确定 1 需要 2 次比较)，新的两种失败情况对应的查找长度为 d+1 和 d+2
$CT_{n-1}$ 成功总长度 $S\cdot(n-1)$，失败总长度 $F\cdot n$
$CT_n$ 成功总长度 $S\cdot(n-1)+(d+2)$，
失败总长度 $F\cdot n+(d+1)+(d+2)-d$
上述结论同样适用于其他版本包括 fibSearch()
## 2-E 起泡排序
【习题 1-3】在对包含 n 个元素的序列做起泡排序的过程中，可能发生以下情况：
1. 某元素会一度(朝着远离其最终位置的方向)逆向移动
![](Images/Pasted%20image%2020241125151052.png)
2. 某元素的初始位置和其最终位置相邻，甚至已经处于最终位置，却需要参与 n-1 次交换
![](Images/Pasted%20image%2020241125151209.png)
![](Images/Pasted%20image%2020241125151335.png)
3. 所有元素都需要参与 n-1 次交换
必为完全逆序的序列
## 2-F 归并排序
## 2-G 位图
【习题2-39】任给 12 个互异的整数，其中 10 个已组织为一个有序序列，现需要插入剩余的两个以完成整体排序。若采用 CBA 式算法，最坏情况下至少需做几次比较？为什么？
前一整数可能插入位置数 \* 后一整数可能的插入位置数 = 11 \* 12 = 132
是对应的代数判定树应含叶节点数目的下限，所以判定树高至少为 $\lceil log_2132\rceil$ = 8，也即最坏情况下需要做比较操作次数的下限
![](Images/Pasted%20image%2020241125230158.png)
![](Images/Pasted%20image%2020241125230441.png)
![|500](Images/Pasted%20image%2020241125230941.png)

# 3 列表
【习题 3-6】![](Images/Pasted%20image%2020241126215927.png)
1. 新元素总是作为首节点被插入
2. 已有的元素一旦接收访问，也随机将其转移到最前端(作为首元素)
【习题 3-10】假定序列中 n 个元素的数值为独立均匀地随机分布
1. 列表的插入排序算法平均需要做约 $\frac{n^2}{4}=O(n^2)$ 次元素比较操作
2. 向量的插入排序算法平均需要做约 $\frac{n^2}{4}=O(n^2)$ 次元素移动操作
和列表不同，向量的插入排序中 search()查找接口可以采用<font color="#ff0000">二分查找</font>之类的算法，从而使复杂度从线性降低到 $O(\log n)$
3. 序列插入排序算法过程中<font color="#ff0000">平均</font>有 expected-O(logn)个元素<font color="#ff0000">不用移动</font>
![](Images/Pasted%20image%2020241126221232.png)
【习题 3-11】列表的插入排序算法中，
1. 若所有逆序对的间距不超过 k，则运行时间为 $O(kn)$
![](Images/Pasted%20image%2020241126221555.png)
2. 由 1 知，当 k 为常数时，插入排序可在线性时间内完成(希尔排序的高效性来源)
3. 若共有 M 个逆序对，则关键码比较的次数不超过 O(M)
   将逆序对计入后者的“帐”上，则所有元素的<font color="#ff0000">逆序前驱</font>的数目总和，应恰好等于 M，结合 1 可知，每个元素所涉及比较操作的次数恰好等于其逆序前驱的数目
4. 若共有 M 个逆序对，则运行时间为 $O(n+M)$
   消耗于比较操作的时间 O(M)，消耗于移动操作的时间 $n\times O(1)$
## 3-F 循环节
* 由选择排序引入
## 3-G 插入排序
【习题 3-16】列表的归并排序中，
1. 若为节省每次子列表的划分时间，而直接令 m = min(c, n/2)，其中 c 为较小的常数，则总体复杂度反而会上升至 $O(n^2)$
   $T(n) = T(c) + T(n-c) + O(n)$
2. 当 c=1 时，算法等效退化为插入排序
## 3-H 归并排序
## 3-I 逆序对
统计逆序对个数
## 3-J 游标
* data：记录数据链头
* free：记录空闲链头
# 4 栈和队列
## 4-B 递归相关
### 4-B3 消除递归
* 递归函数的空间复杂度：
	* 主要取决于最大递归深度
	* 而非递归实例总数
### 4-B4 尾递归
* 容易改写为迭代形式（例如 goto 模拟递归返回）
* 空间复杂度可能会有渐进改进
* 时间复杂度可能有常系数改进
## 4-C 进制转换
* 栈：迭代版
* 递归版
## 4-D 括号匹配
* 消除一对紧邻的左右括号，不影响全局的匹配判断
* 顺序扫描，遇到左括号进栈，遇到右括号出栈
【习题 4-15】![|600](Images/Pasted%20image%2020241127172051.png)
## 4-E 栈混洗
* 栈混洗总数：$$SP(n) = \sum^{n}_{k=1}SP(k-1)\cdot SP(n-k)=\frac{(2n)!}{n!(n+1)!}$$
* 禁形(充要)：{“j+1，i，j”(312)}、{“k，i，j”}
  【习题 4-3】![](Images/Pasted%20image%2020241127161234.png)不一定，例如 B={2，4，1，3}（含禁形 413）
* n 个元素的栈混洗 = n <font color="#ff0000">对</font>括号的匹配 = 由 n 个互异节点组成的 BST
## 4-F 中缀表达式
【习题 4-10】教材 95 页代码 4.7 中的 中缀表达式求值 evalute()算法，对"^"的求值采用了向左优先结合率，比如表达式"2^3^5"被理解为"(2^3)^5"
【习题 4-11】evalute()算法执行过程中的某一时刻，设操作符栈共存有 502 个括号，此时栈的规模(含栈底的'\0')至多可能多大？为什么？
算法执行中的任何时刻，操作符栈中所存每一操作符相对于其直接后继（若存在）的优先级都要（严格地）更高。在（左）括号数固定的条件下，为使操作符栈中容纳更多的操作符，必须使每个（左）括号的上述特性得以充分发挥。具体地，在每个（左）括号入栈之前，应<font color="#ff0000">使每个优先级别的操作符都出现一次</font>（当然，也至多各出现一次）。这里，'+'和'-'同处一级，'\*'和'\/'同处一级，'^'自成一级，'!'也自成一级。注意任何时刻操作符'!'在操作符栈中只可能存在一个，<font color="#ff0000">且必定是栈顶</font>
![](Images/Pasted%20image%2020241127170822.png)
【习题 4-12】evalute()算法输入非正常表达式“(12)3+!4*+5”求值
![|500](Images/Pasted%20image%2020241127171347.png)
## 4-G 逆波兰表达式
### 4-G1 求值

| 24  |
| --- |
| 8   |
| 2   |
2 8 24 - + = (8 - 24) + 2 **栈底减（除）栈顶**
【习题 4-13】尽管 RPN 表达式可以省去括号，但必须在相邻的操作数、操作符之间插入特定的分隔符(通常为空格)。RPN 表达式所引入的分隔符数量和（操作数+操作符）总数相当，所以其所占空间总量未必少于原表达式
### 4-G2 转换
* 手工转化
后缀转中缀
![](Images/Pasted%20image%2020241031095536.png)
中缀转后缀
    加括号，运算符代替右括号，清除左括号
![](Images/Pasted%20image%2020241031095747.png)
* 自动转化
	中缀表达式求值算法附带完成
## 4-H 队列
* 基于向量派生
* 基于列表派生
【4-21】双端队列：允许在头尾插入删除
## 4-J 双栈当队
![|475](Images/1857360-20220714210806132-1672496540.gif)
栈 B 为空时，需先将栈 A 元素转入 B 中，再对栈 B 做 pop
![|475](Images/1857360-20220714210806248-927348673.gif)
## 4-K Steap + Queap
Steap = Stack + Heap = push + pop + getmax
![](Images/Pasted%20image%2020241031110246.png)
* getmax()：return P.top(); // O(1)
* pop()：P.pop(); return S.pop();  //O(1)
* push(): P.push(max(elem, P.top())); S.push(elem);

Queap = Queue + Heap = enqueue + dequeue + getMax
![](Images/Pasted%20image%2020241031112344.png)
* getmax()：return P.front();  // O(1)
* dequeue()：P.dequeue();  return Q.dequeue();  // O(1)
* enqueue()：![|400](Images/Pasted%20image%2020241031113153.png)
  最坏情况需要 O(n)
## 4-L 直方图内最大矩形
[[912 DSA复习笔记##04-L 直方图内最大矩形]]
# 5 二叉树
## 5-A 树
* 节点深度（边数）
	 根节点深度为 0
* 树高度（所有叶子深度中的最大值）
	 空树高度为-1
【习题 5-1】任何一棵二叉树，对其中任一节点 $v\in T$，总有 $depth(v)+height(v)\leq height(T)$，取等的充要条件是什么？
>[!important]-
>节点 v 是全树(某一)最深(叶)节点的祖先
## 5-B 树的表示
1. 父节点表示法(vector)
2. 孩子节点表示法(vector + list)
3. 父节点+孩子节点(2 * vector + list)
4. 长子+兄弟(2 * pointer)
## 5-C 有根有序树=二叉树
- 深度为 k 的节点，至多有 $2^k$ 个
- 边数 $e = n - 1 = 出度和 = n_{1} + 2n_{2}$
- 节点数 $n = n_{0} + n_{1} + n_{2} = 1 + n_{1} + 2n_{2}$
	$n_{1}+2n_{2} = n-1 = n_{0}+n_{1}+n_{2}-1$
	即叶节点数 $n_{0}=n_{2}+1$
- n 个节点，高度 h 的二叉树满足：$$h + 1 \leq n \leq 2^{h+1} - 1$$
* 满二叉树：$n = 2^{h+1} - 1$
* 真二叉树：引入 $n_{1}+2n_{0}$ 个外部节点，其边数必为偶数，节点数必为奇数
* 完全二叉树：叶节点不少于内部节点，不多于内部节点+1
	满足 $2^h \leq n \leq 2^(h+1)-1$
## 5-D 二叉树实现
* 高度更新
【习题 5-4】在逆行向上依次更新 x 各祖先高度的过程中，一旦发现某一祖先的高度没有发生变化，算法即可提前终止
- 子树删除：需要将子树中的节点<font color="#ff0000">递归释放</font>并归还系统，时间复杂度 $O(待删除子树规模)$，空间复杂度 $O(待删除子树高度)$
## 5-E 先序遍历
## 5-F 中序遍历
* 直接后继
![|500](Images/Pasted%20image%2020241127180527.png)
![|500](Images/Pasted%20image%2020241127180733.png)
情况二的特殊情况：若 s 并不存在，t 即为全树最大节点，返回 NULL
## 5-G 后序遍历
* 表达式树~后序遍历~RPN
## 5-H 层序遍历
* 完全二叉树做层序遍历，辅助队列最大规模 ($\lceil  \frac{n}{2}  \rceil$，前 $\lceil  \frac{n}{2}  \rceil-1$ 次都出 1 进 2) 可能出现 2 次
![|500](Images/Pasted%20image%2020241127191247.png)
【习题 5-19】对完全二叉树做层序遍历，整个遍历过程中，辅助队列的规模变化是对称的
![|500](Images/Pasted%20image%2020241127185530.png)
非完全二叉树的遍历过程中，辅助队列的规模仍可能达到 $\left\lceil  \frac{n}{2} \right\rceil$
![|500](Images/Pasted%20image%2020241127191923.png)
【习题 5-20】完全二叉树的层序遍历过程中，按入队(出队)次序从 0 开始将各节点 X 编号为 r(X)，如何判断任何一对节点之间是否存在“祖先-后代”关系？
![|500](Images/Pasted%20image%2020241127193252.png)
【习题 5-11】所有遍历：时间复杂度 O(n)，空间复杂度 O(n)
## 5-I 重构
- 先序|后序 + 中序
- 先序 + 后序 + 真二叉树
- 增强序列：假想认为树中每个 NULL 也是“真实节点”，并在遍历时一并输出
  1. 任一子树依然对应一个子序列
  2. NULL 节点恰比非 NULL 节点多一个（由此得到左子树根和右子树根）
	则通过先序或后序的增强序列可以重构原树
	无法通过中序的增强序列重构
## 5-J Huffman 树
* PFC 编码（前缀无歧义编码）
  不考虑字符频率，真完全二叉树即最优编码树
- 最优编码树（Optimal encoding tree）
  【习题 5-27】考虑字符的出现频率后，最优编码树依然是真二叉树
- Huffman 树
  频率最低的字符 x、y，必在<font color="#d99694">某棵</font>最优编码树中处于最底层，且互为兄弟
# 6 图
## 6-A 概述
- v-v：邻接    v-e：关联
- 简单图、无向图、有向图、混合图、DAG、MST
- 简单路径：不含重复节点
- 欧拉环路：各边恰好出现一次
【习题 6-11】在 O(n+e)时间找到任一无向图的欧拉环路
![|500](Images/Pasted%20image%2020241128192556.png)
![|500](Images/Pasted%20image%2020241128192856.png)
- 哈密尔顿环路：各顶点恰好出现一次
【习题 6-9】无向图中任一顶点 v，其余顶点到它的距离的最大值称为偏心率
![|500](Images/Pasted%20image%2020241128191936.png)
## 6-B 邻接矩阵
- 适用于稠密图
- 判边：O(1)
- 获取顶点度数：O(1)
- 添加、删除边后更新度数：O(1)
- 空间：$\Theta(n^2)$
* 平面图：$e \leq 3n-6$（取等时，每张面恰好由 3 条边围成）
- 压缩存储技术
【习题 6-2】即便计入向量扩容所需时间，<font color="#ff0000">分摊</font>意义上，插入顶点算法的时间复杂度不超过 O(n)（最坏情况下 $O(n^2)$）
【习题 6-4】将二维邻接矩阵映射至一维向量 ![|500](Images/Pasted%20image%2020241127204310.png)
但新顶点的引入和原顶点的删除都可能需要移动向量中的所有元素，得不偿失
## 关联矩阵
有向图中：
![|300](Images/Pasted%20image%2020241127195719.png)
无向图中：
![|300](Images/Pasted%20image%2020241127195839.png)
![|300](Images/Pasted%20image%2020241127200152.png)
【习题 6-1】关联矩阵和邻接矩阵的联系：
![|600](Images/Pasted%20image%2020241127200621.png)
$$
\begin{pmatrix}    1 & 1 & 1 & 1 & 0 & 0\\    1 & 1 & 0 & 0 & 1 & 0\\  0 & 0 & 0 & 1 & 1 & 1\\  0 & 0 & 1 & 0 & 0 & 1\\\end{pmatrix}\begin{pmatrix}    1 & 1 & 0 & 0\\  1 & 1 & 0 & 0\\  1 & 0 & 0 & 1\\  1 & 0 & 1 & 0\\  0 & 1 & 1 & 0\\  0 & 0 & 1 & 1\\\end{pmatrix}=\begin{array}{lc}\mbox{}&\begin{array}{cc}V_1&V_2&V_3&V_4 \end{array}\\\begin{array}{c}V_1\\V_2\\V_3\\V_4 \end{array}&\left[\begin{array}{cc}  4 & 2 & 1 & 1\\  2 & 3 & 1 & 0\\  1 & 1 & 3 & 1\\  1 & 0 & 1 & 2\\\end{array}\right]\end{array}
$$
有向图的关联矩阵和邻接矩阵的联系：
![|600](Images/Pasted%20image%2020241127202549.png)
## 6-C 邻接表
将邻接矩阵的各行组织为<font color="#ff0000">列表</font>，只记录存在的边
- 适用于稀疏图
- 空间复杂度：
	有向图：O(n+e)
	无向图：O(n+2e)
	平面图：O(n + 3n) = O(n)
* 时间复杂度：
	建立邻接表：O(n+e)
	遍历所有邻接表：O(n+e)，建立逆邻接表可改进为 O(1+deg(v))
	计算 v 的度数：增加度数记录域：O(n)附加空间
		增加/删除边时更新度数：O(1)
		每次查询：O(1)
	判边：
		有向图：搜索 u 的邻接表 O(deg(u))
		无向图：搜索 u 或 v 的邻接表 O(max(deg(u), deg(v)))
		通过散列：O(1)，增加 O(n+e)的空间
## 6-D BFS
- 时间复杂度：O(n+e)
- 有向图/无向图都会出现 TREE 和 CROSS
UNDISCOVERED：未入队
DISCOVERED：在队列中
VISITED：已出队列
- TREE：v(DISCOVERED)->u(UNDISCOVERED)
- CROSS：v(DISCOVERED)->u(DISCOVERED/VISITED)
对图做 BFS 会生成一个 BFS 森林，包含 c 棵树，n-c 条 TREE（n 个点，如果只有一棵树则有n-1 条边），e-n+c 条 CROSS
- 最短路径：无向图中，顶点 v 到 u 的(最近)距离记作 dist(v, u)
  TREE 联接的顶点：dist(source)恰好差 1
  CROSS 联接的顶点：dist(source)至多差 1
## 6-E DFS
- 时间复杂度：O(n+e)
- 有向图会出现 CROSS ，无向图不会出现
UNDISCOVERED：未入栈
DISCOVERED：在栈中
VISITED：已出栈
- TREE：v(DISCOVERE)->u(UNDISCOVERED)
- BACKWARD: v(DISCOVERED)->u(DISCOVERED) （后代指向祖先，且说明至少有一个回路）
- FORWARD: v(DISCOVERED)->u(VISITED) && dTime(v) < dTime(u) （祖先指向后代）
- CROSS: v(DISCOVERED)->u(VISITED) && dTime(v) > dTime(u) （表亲，MST 中除根节点没有公共祖先或后代）
DFS 森林所有边数都不唯一
![|400](Images/Pasted%20image%2020241128213236.png)
括号引理
## 6-F 拓扑排序
- 零入度算法 O(n+e)
- 零出度算法（对图做 DFS，当节点标记为 VISITED，入栈，DFS 结束后弹出栈内元素）O(n+e)
# 7 图应用
![|650](Images/Pasted%20image%2020241128201657.png)
## 7-A 优先级搜索
- 通过优先级数越大，优先级越低
## 7-B MST
### 7-B1 Prim
- 合成数消歧
- 含负权环依然可行
- 完全图：无向图，其中每一对不同的顶点都只有一条边相连
- Cayley 公式：联接 n 个互异顶点的树共有 $n^{n-2}$ 棵，完全图 Kn 有 $n^{n-2}$ 棵支撑树
假设有连通图 $G=\{V,E\}$，e 是其中一条边（即 $e \in E$），如果 $G-e$ 是不连通的，则边 e 是图 G 的一条割边（桥）
- 对于极短割边（跨边）uv，必存在一棵包含 uv 的 MST
- 【习题 6-27】由极短割边（跨边）构成的支撑树，未必就是一棵 MST
![|650](Images/Pasted%20image%2020241128200237.png)
【习题 6-18】MST 还可能采用同一割的其他跨边
![|650](Images/Pasted%20image%2020241128195006.png)
### 7-E Kruskal 算法
- 利用并查集判断新加入的边会不会形成回路
- 最坏情况需要检查 $\Omega(n^2)$ 条边
- O(elog e)
## 7-C 最短路径
### 7-C1 Dijkstra
- 任意最短路径前缀，也是一条最短路径
- 需要保证各边权重为正
![|250](Images/Pasted%20image%2020241128195754.png)
### 7-F Floyd-Warshall 算法
- 所有点对之间的最短距离
- 允许负权边，但不能有负权环路
- DP
## 7-D （点）双连通分量
无向图的关节点：删除后原图的连通分量增多
没有关节点的图称作双连通图（即删除图中任意节点，图的连通分量数保持不变）
双连通分量：极大的双连通子图
- DFS 树的叶节点一定不是关节点
- 根节点：如果有 2 棵子树，必定是关节点
- 内部节点 v：有某个孩子 u，且 subtree(u)无法由 BACKWARD 边联接到 v 的任何真祖先，则 v 对 u 而言是关节点
- O(n+e)
- 空间复杂度：除了原图本身，还需要一个O(e)的栈存放已访问的边，和 O(n)的运行栈
# 8 BST
## 8-A~C 概念
- 任意一节点均不小于/不大于左/右后代
- 中序遍历序列单调非降(充要条件)
- n 个节点的 BST 查找最坏时间 O(n)
- 新节点作为叶子插入
- 删除分为单分支和双分支
假设各排列出现的概率均等 $\frac{1}{n!}$，则按随机排列依次插入生成的 BST 平均高度为 $\Theta(\log n)$
n 个互异节点随机组成的 BST 共有 Catalan(n) 棵
假设所有 BST 等概率出现，则平均高度为 $\Theta(\sqrt{ n })$
- 等价 BST：中序遍历次序保持，上下联接关系变化
- 经过不超过 O(n) 次旋转，等价的 BST 均可相互转化
【习题 7-10】
![](Images/Pasted%20image%2020241128214803.png)
针对 $(e-\epsilon,\ e+\epsilon)$ 各做一次查找，并确定查找路径终点的最低公共祖先；在从公共祖先通往这两个终点的路径上，自上而下地根据各层的分支方向，相应地忽略整个分支
![|650](Images/Pasted%20image%2020241128215341.png)
【习题 7-15】
1. 规模为 n 的任何 BST 经过不超过 n-1 次旋转调整都可以等价变换为仅含左分支的 BST
   - 右子树为空，转到父节点继续处理
   - 右子树不为空，反复做 zag
![|600](Images/Pasted%20image%2020241128221833.png)
2. 规模为 n 的任何两棵等价 BST 至多经过 2n-2 次旋转调整，即可彼此转换
## 8-D AVL
- 平衡因子：balFac(v) = height(<font color="#d83931">lc</font>(v)) - height(<font color="#d83931">rc</font>(v))，$\mid balFac(v)\mid \leq 1$
- 高度为 h 的 AVL 树，至少包含 $S(h) = fib(h+3) - 1$ 个节点（S(0) = 1）
- 【习题 7-12】高度为 h 的 AVL 树中，任一叶节点深度均不小于 $\left\lceil  \frac{h}{2} \right\rceil$
- 插入：从<font color="#d83931">祖父</font>开始，每个祖先都有可能失衡，其可能同时失衡，但修正不会引发失衡传播
- 删除：从<font color="#d83931">父亲</font>开始，每个祖先都有可能失衡，但至多一个，修正会引发失衡传播，且无论是否做过调整，全树高度都有可能下降
  【习题 7-19】
- 3+4 重构
优点：
- 无论查找、插入或删除，最坏情况下的复杂度均是 O(log n)，O(n)的存储空间
缺点：
- 需要引入平衡因子
- 删除操作后，最多需要旋转 $\Omega(\log n)$ 次（平均仅 0.21 次）
- 单次动态调整后，全树拓扑结构的变化量可能高达 $\Omega(\log n)$
# 9 BST 应用
## 9-A 范围查询
用于引入 kd 树
KD 树就是把数据所在的空间划分为特定的几个部分，然后在特定空间的部分内进行相关搜索操作
## 9-B kd 树
数据(2, 3), (5, 4), (9, 6), (4, 7), (8, 1), (7, 2)在二维平面表示如下：
![](Images/Pasted%20image%2020241102153625.png)
- 第一轮：找到数据第一维度的中位数进行划分
  数据按第一维度排序为：(<font color="#d83931">2</font>, 3), (<font color="#d83931">4</font>, 7), (<font color="#d83931">5</font>, 4), (<font color="#d83931">7</font>, 2), (<font color="#d83931">8</font>, 1), (<font color="#d83931">9</font>, 6)，数据集大小 k=6，选取第 k/2+1=4 个点作为中位数点->(7, 2)进行划分，将平面划分为左右两个部分，并将该点加入KD树的二叉树结构中作为根节点
![](Images/Pasted%20image%2020241102154208.png)
划分完后，左右区域均有未划分节点，先划分左区域
- 第二轮：找到左区域数据第二维度的中位数进行划分，排序得 (2, <font color="#d83931">3</font>), (5, <font color="#d83931">4</font>), (4, <font color="#d83931">7</font>)。数据集大小 k = 3，选取第 k/2+1=2 个点即“中位数”点->（5, 4）作为分界线进行划分，将平面划分为上下两个部分，并将该点加入KD树的二叉树结构中作为根节点的左儿子节点
![](Images/Pasted%20image%2020241102154651.png)
划分完后，上下区域均有未划分节点，先划分下区域
- 第三轮：找到下区域数据第一维度的中位数进行划分，当前区域仅有点(2,3)，将平面划分为左右两个部分，并将该点加入KD树的二叉树结构中作为第二轮划分的节点的左儿子节点
![](Images/Pasted%20image%2020241102154904.png)
划分完后，左右区域均无未划分节点，直接递归回溯处理第二轮划分产生的上区域
![](Images/Pasted%20image%2020241102154941.png)
划分完后，左右区域均无未划分节点，回溯发现第二轮的上下划分区域均处理完毕，直接递归回溯处理第一轮划分产生的右区域
![](Images/Pasted%20image%2020241102155017.png)
![](Images/Pasted%20image%2020241102155030.png)
查询
如果当前子树对应的矩形（范围）与所求矩形（范围）没有交点，则不继续搜索其子树；如果当前子树对应的矩形完全包含在所求矩形内，返回当前子树内所有点的权值和；否则，判断当前点是否在所求矩形内，更新答案并递归在左右子树中查找答案。
## 9-C~XC 其他树
# 10 高级搜索树
## 10-A 伸展树
- 逐层伸展：最坏情况：分摊 $\Omega(n)$
- 双层伸展：zig-zag/zag-zig 没有区别
  zi(a)g-zi(a)g 先从祖父节点开始旋转，节点访问后，对应路径长度折半，分摊 O(log n)，不能避免最坏情况发生，但可以保证不会持续发生
- 任意一颗伸展树，按节点值的大小升序依次访问完所有节点，最后树将变为一条左单链
查找：无论查找是否成功，都将最后访问的节点伸展到根
插入：找到待插入位置时，\_hot 会被伸展到根，沿根断开并接入新节点做新根
删除：找到待删除节点 x 时，待删除节点 x 会被伸展到根，找到其前驱后继，分别是其左子树中的最靠右的节点和其右子树中最靠左的节点，假设其前驱节点为 y，其后继节点为 z，把节点 y 伸展成根节点，再把节点 z 伸展成根节点的右儿子，这样节点 z 的左子树必然只有一个节点 x，把它删掉
- 越平衡的树，势能越小，单链势能=log n! =  O(n log n)，满树势能=O(n)
优点：
- 分摊复杂度 O(log n)
- 局部性强，缓存命中率极高时：任意连续的 m 次查找，查找范围 k，总数据范围 n（k << n << m），仅需 O(m log k + n log n)时间
- 反复顺序访问任一子集，分摊成本仅为常数
缺点：
- 不能杜绝单次最坏情况，不适用于对效率敏感场合
## 10-B B-树
- B-树每一层代表一级存储结构
- m 阶 B-树，内部节点关键码：$\left\lceil  \frac{m}{2} \right\rceil - 1 \leq n \leq m-1$
		  内部节点分支数：$\left\lceil  \frac{m}{2} \right\rceil \leq n \leq m$
		  树根节点关键码：$1\leq n\leq m-1$
		  树根节点分支数：$2\leq n\leq m$
- B-树叶节点深度=高度-1，外部节点深度=高度
- BTNode 用一组向量存储关键码，一组向量存储分支指针
- N 个内部节点，N+1 个外部节点
- B 树高度：$\log_{m}(N+1) \leq h \leq 1 + \log_{\left\lceil  \frac{m}{2}  \right\rceil} \lfloor \frac{N+1}{2} \rfloor$
- 有多少次外存操作就有多少次内存操作
查找：
- 约定：根节点常驻内存
- 查找是由一系列在内存中的顺序查找和 I/O 操作间隔完成
- 忽略内存中的查找，运行时间主要取决于 I/O 次数
插入：
- 发生上溢，取中位数 $s= \lfloor \frac{m}{2} \rceil$，分为 $\{k_{0},\dots,k_{s-1}\}、\{k_{s}\}、\{k_{s+1},\dots,k_{m-1}\}$
删除：
- 非叶节点找到其后继节点，后继节点必定是最底层某超级节点的第一个节点，交换位置，转为删除叶节点
- 若下溢：先找左右兄弟借（旋转），都借不了则合并
插入和删除操作不对称：牺牲一点效率换取实现简明
B\*树联合分裂：
- 由 k 个兄弟共同均摊溢出的关键码
- 空间利用率相比于 B 树（50%）提高至 $\frac{k}{k+1}$
##  10-C 红黑树
统一增设外部节点 NULL，使之成为真二叉树
1. 黑根
2. 黑外部节点
3. 不能双红
4. 外部节点：黑深度（黑的真祖先数目）= 根（全树）的黑高度 相等
- 所有的 AVL 树都可以染成红黑树，AVL 树对于左右子树的高度平衡要求比红黑树更严格
- 包含 n 个内部节点的红黑树高度：$\log_{2}(n+1)\leq h\leq 2*\log_{2}(n+1)$
- 树高 h，黑高 H，红高 R，$H\leq h\leq R+H\leq 2*H$
[如何记忆红黑树的操作](https://martinlwx.github.io/zh-cn/how-to-memorize-insertion-and-deletion-in-rb-tree/)
![|400](Images/Pasted%20image%2020241104165740.png)
特别注意：第二种节点映射意味着可以做等价结构变化
**插入：**
插入位置必定是叶节点
插入红节点，如果为根，则染黑
只可能出现双红问题
- 插入节点的父节点为黑，不存在双红问题，不必调整
- 插入节点的父节点为红，且不存在 uncle 节点
![|400](Images/Pasted%20image%2020241104170325.png)
- 插入节点的父节点为红，且存在 uncle 节点（RBTree拓扑结构未变）
![|400](Images/Pasted%20image%2020241104170437.png)
![|400](Images/Pasted%20image%2020241104170546.png)
![|400](Images/Pasted%20image%2020241104170806.png)
复杂度：最多 O(log n)次重染色，O(1)次结构调整

**删除：**
找到待删除节点的后继节点并交换节点内容，待删除节点至多只有一个右孩子
- 待删除节点没有孩子
	- 待删除节点为红，直接删除
	- 待删除节点为黑，将两个外部 NULL 节点视作两个黑色孩子
- 待删除节点有红色右孩子，直接替代并染黑
![|400](Images/Pasted%20image%2020241104171346.png)
- 待删除节点有黑色右孩子![|400](Images/Pasted%20image%2020241104171454.png)"double black"是指需要这里有 2 个黑色节点，删除 “z” 缺少了一个黑节点
	- (BB-1)如果兄弟节点是黑色且至少有一个红色孩子（对应 B 树下溢借节点）![|400](Images/Pasted%20image%2020241104171753.png)
	- (BB-2)如果兄弟节点是黑色且有两个黑色孩子（对应 B 树下溢合并节点）![|400](Images/Pasted%20image%2020241104171951.png)
		- (BB-2R)如果节点 5 是红色，则将 5 染黑就可以解决 double black
		- (BB-2B)如果节点 5 是黑色，则 double black 从 4 转移到 5 处继续调整
	- (BB-3)如果兄弟节点是红色（等价变化为兄弟节点是黑节点，转为情况BB-2 R 或者 BB-1）![|400](Images/Pasted%20image%2020241104173152.png)
复杂度：至多 O(log n)次重染色，1 次 “3+4” 重构，一次单旋
红黑树结构调整复杂度 O(1)
# 11 散列
- 装填因子：散列表中元素的数量 N/ 散列表大小 M
- 完美散列：数据集已知且固定可以实现
## 11-B 散列函数
越是随机，越是没有规律越好
- 除余法：hash(key) = key%M
  缺陷：
	  1. 不动点，hash(0) = 0
	  2. 相关性，相邻关键码的散列地址必定相邻
- MAD：hash(key) = (a * key + b) % M （M 是素数）
- 数字分析：抽取 key 中某几位，构成地址
- 平方取中：取 ${key}^2$ 的中间若干位，构成地址
- 折叠法：将 key 分割成等宽的若干段，取其总和作为地址
- 位异或法：将 Key 分割成等宽的二进制段，经异或运算得到地址
- 伪随机数法：$hash(key) = rand(key) = [rand(0) * a^{key}] \% M$
  缺陷：
	  伪随机数发生器在不同环境可能不同，创建的散列表可移植性差
- 多项式法：$hashCode('X_{n-1}\dots X_{0}') = \sum{X_{n-i}a^{n-i}}$
## 11-C 排解冲突
开放散列：用散列表以外的开放地址
- 多槽位：将桶单元细分成若干槽位存放（与同一单元）冲突的词条
- 独立链：每个桶拥有一个列表，存放一组同义词
  主要缺陷：空间未必连续分布，系统缓存难以生效
- 公共溢出区：单独开辟出一块连续空间
封闭散列：只用散列表的空闲封闭地址
开放定址：任何散列桶都可以接纳任何词条（开放散列中如独立链，对应列表只能存放与此桶单元冲突的词条）
**封闭散列必定对应于开放定址**
- 线性试探：$[hash(key)+i]\%M$（i 是冲突次数）一旦发生冲突，则试探紧邻的下一个桶
	  优势：可用充分利用系统缓存
	  缺陷：数据堆积现象严重，可能出现连续冲突
	- 懒惰删除：懒惰标记被删除的桶
	  查找：看作是不匹配的非空桶
	  插入：看作是匹配的空闲桶
- 平方试探：$[hash(key)+i^2]\%M$ 以平方数为距离，确定下一试探桶单元
	  优势：缓解数据聚集现象
	  缺陷：一定程度上破坏局部性
	  若 M 是素数，且装填因子≤0.5，只要有空桶就必然能找出来
- 双向平方试探法：$\left[ hash(key)+(-1)^i * \lceil\frac{i}{2}\rceil^2 \right] \%M$，间或地沿两个方向试探
	  表长取作素数 $M=4*k+3$
	  $M = 4*k+1$ 必然不能使用
- 再散列：预先约定第二散列函数：$hash_{2}(key, i)$ 或者 $hash_{2}(key)$，冲突时确定<font color="#d83931">偏移增量</font>得到下一试探位置：$[hash(key)+\sum^{k}_{i=1}hash_{2}(key,i)]\%M$ 或者 $[hash(key)+i*hash_{2}(key)]\%M$
	  线性试探：$hash_{2}(key, i)=1$
	  平方试探：$hash_{2}(key,i)=2i-1$
- 重散列：将词条重新散列到更大容量的新散列表中
	  插入：若装填因子＞50%，重散列
	  删除：若懒惰删除标记过多，重散列
## 11-D 桶排序
[[912 DSA复习笔记##11-D 桶排序]]
## 11-E 基数排序
[[912 DSA复习笔记##11-E 基数排序]]
## 11-F 计数排序
[[912 DSA复习笔记##11-F 计数排序]]
## 11-G 跳转表
[[912 DSA复习笔记##11-G 跳转表]]
# 12 优先级队列
## 12-B 完全二叉堆
- 逻辑上：完全二叉树
- 物理上：向量
- 内部节点的最大秩：$\left\lfloor  \frac{n-2}{2}  \right\rfloor = \left\lceil  \frac{n-3}{2} \right\rceil$
插入：
- 逐层上滤：插入元素到向量末尾，调整元素和其父节点
删除：
- 逐层下滤：用末元素代替堆顶，找到末元素及其两个孩子的最大者
批量建堆：
- 自上而下的上滤：自上而下，自左而右，逐一对每个节点做上滤，等价于不断插入节点到堆
  时间复杂度：O(nlog n)（节点深度和）优势：在线算法
- 自下而上的下滤：自下而上，自右而左，逐一对各<font color="#d83931">内部节点</font>做下滤，等价于子堆逐层合并
  时间复杂度：O(n)（节点高度和）
大顶堆的 delMin()操作无法在 O(log n)时间完成，需要借助 min-max 堆
## 12-C 堆排序
[[912 DSA复习笔记##12-C 堆排序]]
## 12-D 锦标赛树
[[912 DSA复习笔记##12-D 锦标赛排序]]
## 12-E 多叉堆
- d 叉堆
	$parent(k) = \lfloor \frac{k-1}{d} \rfloor$
	$child(k,i)=k*d+i,0<i\leq d$
	d 不是 2 的幂时，将不能借助移位加速运算
	- 堆高降至：$O(\log_{d} n)$，上滤成本降至 $O(\log_{d} n)$
	- 下滤成本增至：$d\cdot{\log_{d}n}$ (d+1 个数中选取 min，需要 d 次比较)
- d=3 时最小，d=4 > d=2 > d=3
在 Dijkstra 或者 Prim 等算法中，需要维护和更新顶点优先级：
1. heapify()：O(n)
2. delMax()：依次取优先级最高的顶点 $O(n\cdot d\cdot log_{d}n)$
3. increase()：更新所有关联顶点的优先级 $O(e\cdot\log_{d} n)$
总运行时间：$O((n\cdot d+e)\cdot \log_{d}n)$，当 $d\approx \frac{e}{n}+2$ 时，总体性能达到最优
对稀疏图保持高效：$e\cdot \log_{\frac{e}{n+2}}n\approx n\cdot \log_{\frac{n}{n+2}}n=O(n\log n)$
对稠密图改进极大：$e\cdot \log_{\frac{e}{n+2}}n\approx n^2\cdot \log_{\frac{n^2}{n+2}}n\approx O(e)$
- Fibonacci 堆
	delMax() O(log n)
	insert() O(1)
	merge() O(1)
	increase() O(1)
$O((n\cdot d+e)\cdot \log_{d}n)\to n\cdot O(log n)+e\cdot O(1)$
## 12-F 左式堆
引入外部节点转为真二叉树
- $npl(NULL) = 0$
- $npl(x) = 1+\min(npl(x.lc), npl(x.rc))$
$npl(x)$：节点到外部节点的<font color="#d83931">最近距离</font>
	以节点为根的最大满子树高度
左式堆：对任何内部节点都有 $npl(x.lc)\geq npl(x.rc)$
	推论：
		- $npl(x.lc) = npl(x.rc)+1$
		- 左式堆的子堆必是左式堆
		- 左式堆倾向于更多节点分布在左侧分支
		- 左式堆的左子堆规模和高度可能小于右子堆
记左式堆根节点为 r，右侧链长度为 d：
	1. $npl(r)=d$
	2. 至少包含：$2^d-1$ 个内部节点，$2^{d+1}-1$ 个节点
	3. 包含 n 个节点的左式堆，右侧链长度 $d\leq \lfloor\log_{2}(n+1)\rfloor-1=O(\log n)$
合并：
[[912 DSA复习笔记### 12-F3 合并]]
插入：将待插入的节点视作只含一个节点的左式堆进行合并
删除：将根节点的左、右子堆合并
# 13 串
- 空串：$S[0, n=0)$ 是任何串的子串、前置、后缀
- m：模式串长度
- n：文本串长度
- 约定在每个字符串末尾有一个'\0'哨兵，串长不计入尾部哨兵
## 13-B 蛮力算法
- 最好情况：一次匹配就成功 $\Omega(n)$
- 最差情况：$O(n\cdot m)$
## 13-C KMP
- 特别适用于顺序存储介质
- 单次匹配概率越大（字符集规模越小），优势越明显
## 13-D BM-BC
- BC：单次匹配概率越小，优势越明显
## 13-E BM-GS
## 13-F karp-Rabin
- 快速指纹计算
## 13-G 键树(trie)
![](Images/Pasted%20image%2020241105193140.jpg)
# 14 排序
## 14-A 快速排序
- 递归深度：最坏情况 $\Omega(n)$，平均情况 $O(\log n)$，假设 pivot 落在宽度为 $\lambda \cdot n$ 的居中区间，若 $\lambda> \frac{1}{3}$ ，至少有 $1-n^{-2}$ 的概率使递归的深度不超过 $\frac{1}{\lambda}\cdot \log_{\frac{2}{1+\lambda}}n = 3\cdot \log_{\frac{3}{2}}n$
- 比较次数（后向分析）：$T(n) \approx 2\cdot n\cdot \ln n \approx 1.386\cdot n\log n$

|     | 比较次数                           | 移动次数(对实际性能影响更大)             |
| --- | ------------------------------ | --------------------------- |
| 快排  | 平均 O(1.39 nlogn)<br>且高概率接近<br> | 平均不过 O(1.39 nlogn)<br>且实际更少 |
| 归并  | 严格 O(nlogn)                    | 严格 O(nlogn)，实际往往加倍          |
- DUP 版：当序列中存在大量元素重复，pivot 位置总是接近于 lo，二分递归退化为线性递归
  从两端交替的向中间扫描 lo->pivot<-hi，处理重复元素时 lo 和 high 会交替移动，且移动距离大致相等，pivot 位置接近 $\frac{lo + hi}{2}$
  DUP：G向左扩展，直到遇到<font color="#d83931">不大于</font>轴点者，L 向右扩展，直到遇到<font color="#d83931">不小于</font>轴点者
  LUG：<font color="#d83931">小于</font>轴点者归入 L，<font color="#d83931">大于</font>轴点者归入 G
## 14-B 选取
## 14-C 希尔排序
- PS 序列$H_{PS} = \{2^k-1|k\in N\}$    $O(n^{\frac{3}{2}})$
- Pratt 序列 $H_{Pratt} = \{2^p\cdot 3^q|p,q\in N\}$    $O(n\log^2n)$
- Sedgewick 序列(PS 和 Pratt 的结合) $H_{Sedgewick} = \{9*4^k-9*2^k+1|k\geq 0\}\cup\{4^k-3*2^k+1|k\geq 2\}$    最差 $O(n^{\frac{4}{3}})$，平均 $O(n^{\frac{7}{6}})$
