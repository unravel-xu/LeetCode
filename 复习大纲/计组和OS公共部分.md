# 异常和中断
## 异常
异常：来自 CPU 内部，硬件打断，系统调用以及其他打断程序正常运行流程的事件
中断：异步发生，来自外部设备，不是由专门的指令造成的，而是通过引脚发送信号并将异常号(标识引起中断的设备)放在系统总线上来触发中断
![|500](Images/Pasted%20image%2020241113181120.png)
若异常/中断处理程序能解决问题，则回到第 i 条指令或第 i+1 条指令继续执行
若是不可恢复的致命错误，则终止用户进程，通常具体处理过程全部由 OS 软件完成
各类异常发生的流水段不同，在每条指令执行结束时，会检测有没有中断请求
- IF 检出：无效指令地址
- ID 检出：无效指令、除数为 0
- EXE 检出：溢出，无效数据地址(lw、sw 指令)
- MEM 检出：对只读区域进行写操作的异常等
相关寄存器：
- 协处理器：处理器的一个<font color="#ff0000">可选</font>部件，负责处理指令集的某个扩展
- CP0：MIPS 的系统控制协处理器，用于处理难以用常规指令解决的问题，CPU 配置，Cache 控制，异常、中断控制、存储管理控制等，包含一系列寄存器
- SR(Status Register)状态寄存器：
	 EXL 段：异常级别，进入内核态，禁止中断
- Cause：导致中断或异常的原因
	  BD 段：是否在延迟槽中
	  IP 段：中断源
	  ExcCode：异常代码
- EPC(Exception Program Counter)异常程序计数器：异常/中断结束后从哪里开始重新执行
	  多周期 CPU：
		  - 中断：指令执行完成后检查中断源，EPC=PC
		  - 异常：指令执行错误后，EPC=上一条指令的地址
	 指令流水 CPU
		 *精确异常*
- BadVaddr Register：访存错误发生时虚拟地址
	  当内存访问出错时保护
	  可用于后续对 TLB 的维护
- 精确异常：在处理异常时，产生异常的位置之前的命令都执行完毕，异常受害指令和其之后的好像从来没有开始一样(异常结束后重新执行，这些指令的行为和异常没有发生时完全一样)，当异常是精确异常时，处理异常的软件就可以忽略 CPU 实现的时序影响。
MIPS 异常处理流程：
1. 保存断点和程序状态：设置 EPC 指向重新开始的地址
   - PC->堆栈或 EPC
   - PSWR(PSW 寄存器，存放程序状态的寄存器)->堆栈或 EPSWR
2. 关中断：设置 SR(EXL)位，强制 CPU 进入内核态，并禁用中断
3. 保存异常原因：设置 Cause 寄存器，在地址异常时，BadVAddr 也要设置
   - 软件识别(MIPS)：OS 使用一个统一的异常处理程序查询 Cause
   - 硬件识别(向量中断 x86)：用硬件查询电路识别异常，得到<font color="#ff0000">中断类型号</font>，到<font color="#ff0000">中断向量表</font>中读取对应的中断服务程序<font color="#ff0000">入口</font>地址
4. 从异常入口点取指令，<font color="#ff0000">之后的事情交给软件处理</font>
5. 保存现场：通过 k0 和 k1 寄存器引用一段可以<font color="#ff0000">保存其他寄存器</font>的内部空间来实现
6. 读取异常原因，识别中断源：区分不同的异常，Cause 寄存器的 ExcCode 域
7. 构造异常处理内部空间：异常处理程序可能由高级语言编写，需要保留通用寄存器，构造堆、栈存储区
8. 处理异常
9. 恢复现场：恢复寄存器，清零 Cause 寄存器
10. 恢复断点：ERET 指令返回 EPC 指向的地址
11. 开中断：ERET 指令复位 SR(EXL)

异常嵌套：嵌套异常的服务程序必须用一部分主存空间来保存寄存器的值，使用的数据结构叫异常帧，多个嵌套异常的异常帧通常保存在栈中

MIPS 中断控制设计：
- 在中断发生时，如果指令已经完成了 MEM 段的操作，则保证该指令执行完毕
- 否则，丢弃流水线上这条指令的工作

磁盘访问过程：对磁盘的访问总是由缺页引起的
1. CPU 给出地址，需要访问某存储单元
2. 进行 TLB 查找和 cache 查找
3. TLB 查找后声明没有找到
4. 停止并行查找，并通知 OS 处理
5. OS 检查页表，发现缺页
6. OS 从主存中选择一页准备换出
	1. 若换出的页是脏页，需要将其写回磁盘存储
	2. OS 申请 I/O 总线
	3. 获得批准后，发送写命令给 I/O 设备(磁盘)，紧跟着传送需要写回的页的全部数据
	4. I/O 控制器发现发给自己的写命令，加入到握手协议，并接受数据
	5. 根据数据要写入的地址，读/写头移动到正确的柱面，同时将数据接受到缓冲区
	6. 寻道结束后，等待相应的扇区旋转到磁头下，将数据写入扇区中
	7. 在写入数据间隙，计算校验码并写入扇区中
7. OS 继续申请总线(如果还保持总线控制权，则不必申请)
8. 得到授权后，向磁盘发出读命令
9. 然后，磁盘识别地址，并转换为相应的地址段
10. 寻道，将读/写头移动到指定位置
11. 从指定扇区中读取数据，并进行校验
12. 磁盘申请 I/O 总线
13. 得到授权后，将数据通过总线送到内存
缺页异常的处理流程
<img align="left" src ="G:/LeetCode/复习大纲/Images/Pasted%20image%2020241118155056.png">1.CPU 读内存单元，在 TLB 中根据其虚拟地址匹配物理地址，未命中，读页表
2.由于页表项的存在位为 0，CPU 产生缺页异常
3.OS 查找到保存在外存中对应的应用的页面内容
4-1 如果有空闲物理页帧，把内存中的页面内容换入到某空闲物理页帧中
4-2 如果没有空闲的物理页帧，通过置换算法释放/换出某物理页帧到外存，再把外存中的页面内容换入到某空闲物理页帧中
5.修改页表项，建立虚拟页到物理页帧的映射，存在位->1
6.OS 返回到应用程序，让处理器重新执行产生缺页异常的读内存单元指令
## 中断
相关概念：
- 中断源
	外中断：I/O 设备等
	异常(内中断)：处理器硬件故障、程序“出错”，Trap
	中断触发器
	中断状态寄存器
- 中断请求
	中断源设备设置中断触发器
		每个中断源有 1 个中断触发器
		同时可设置 1 个中断屏蔽触发器
- 中断响应
	响应条件
		允许中断、当前指令结束、优先级
	响应实现
		硬件实现的中断隐指令，保存断点
![](Images/Pasted%20image%2020241116224350.png)
## 习题
1. 以下哪个不是 MIPS 响应异常的硬件处理（）
   (A)保存 PC
   (B)保存通用寄存器
   (C)保存异常原因
   (D)恢复 PC
   选(B)、(D)
2. MIPS 中断中不是由硬件负责的是（）
   (A)保存断点
   (B)保存寄存器
   (C)关中断
   (D)保存异常原因
   选(B)
3. MIPS 尽管只有一套控制寄存器，但是也可以中断嵌套（√）
   是通过在内存中开辟一块区域保存上下文信息
4. 指令在（ ）阶段不会发生异常
   (A)取指 (B)执行 (C)访存 (D)写回
   IF 段可能发生缺页异常，要取的指令不在内存中
   EXE 段可能产生除以 0 异常等算术异常
   MEM 阶段可能发生对只读区域进行写操作的异常等异常
   选(D)
# RAID
![|500](Images/Pasted%20image%2020241122193523.png)
数据条带化：把一段连续的数据分割成相同大小的数据块，并将其分别写入到阵列中的不同磁盘上，使得多进程可以并发访问
## RAID0
没有冗余，可靠性差，数据条带化
![|500](Images/Pasted%20image%2020241114111702.png)
![|500](Images/Pasted%20image%2020241122193116.png)
如果 I/O 请求访问不同盘上的数据，可以并行发送
## RAID1
镜像盘实现 1：1 冗余，没有数据条带化
![|300](Images/Pasted%20image%2020241114154304.jpg)
写：并行写，受限于写的慢的盘，性能稍微下降
读：提高 2 倍，虽然没有数据条带化，但考虑第一块提供 Block1，第二块提供 Block2
检错：直接从镜像盘恢复
可靠性高，成本高
## RAID2
![|500](Images/Pasted%20image%2020241114112532.png)
工作单位是字/字节，基于“位”的条带化
驱动器严格同步
用海明码生成多个冗余校验盘，实现一位纠错，两位检错
读：操作性能提高（多盘并行）
写：同时写数据盘和校验盘
## RAID3
![|500](Images/Pasted%20image%2020241114113219.png)
工作单位是字/字节，基于“位”的条带化
驱动器严格同步
是 RAID2 的简化版本，只对每个字计算一个奇偶校验位
读：操作性能提高（多盘并行）
写：同时写数据盘和校验盘
## RAID4
![|500](Images/Pasted%20image%2020241114161803.png)
独立访问
和 RAID0 类似，但和 RAID2、3 区别在于按块校验而不是按位校验
每个磁盘的操作独立进行，可以同时响应多个 I/O 请求
对盘上部分字节数据出错的纠错性能很差
校验盘负载很大
## RAID5
![|500](Images/Pasted%20image%2020241114162619.png)
独立访问，允许一个磁盘错误
将校验位循环均匀分布到所有的驱动器上
## RAID6
![|500](Images/Pasted%20image%2020241114164202.png)
独立访问
PA：数据块 A 的校验值
P0：第 0 条块的校验值
采用双维块奇偶校验，允许双盘出错
应用于数据绝对不能出错的场合
## RAID7
![|500](Images/Pasted%20image%2020241114164750.jpg)
自身就带有实时操作系统和用于存储管理的软件工具，可完全独立于主机运行
有两个独立的 cache 双工运行，在 Cache 中完成校验
## RAID01
即 RAID0+1
![](Images/Pasted%20image%2020241114112314.png)
## RAID10
![|440](Images/Pasted%20image%2020241122193736.png)
## 习题
1. RAID6 坏两个磁盘也可以工作（√）
2. 存储 100MB 的数据，RAID1 的磁盘的大小为 200MB，RAID5 的磁盘的大小为 125MB
3. 一个 4+1 的 RAID5 磁盘组织，同一个地址在前四个磁盘中的数据分别为 0x11,0x22,0x33,0x44，此时第五个磁盘出错，新磁盘替换后，新磁盘中该地址上的数据初始化为
   $0x11\oplus0x22\oplus0x33\oplus0x44 = 0x44$
4. RAID1 比不使用 RAID 读写更快 (×)
   写性能略差于不使用 RAID
# Cache
- 用高速的静态存储器实现
- 完全硬件管理，对程序员透明
- 有些数据不能存放在 cache 中(例如内核空间 kseg1 区域是非映射非缓存区域，被固定映射在物理空间最开始的区间，无须 MMU 转换)
块(行、槽)：数据交换的最小单位
![](Images/Pasted%20image%2020241116152605.png)
V：有效位
M：脏位
失效损失：替换较高层次数据块的时间+将该块交付给处理器的时间
平均访问时间：命中率 \* 命中时间 + (1-命中率) \* 失效损失
## 映射方式
1. 直接映射(只能放固定位置)
![](Images/Pasted%20image%2020241116111947.png)
利用率低，命中率低，效率较低
假设 Cache 容量 64KB，块大小 16B，物理地址 32 位，按字节编址
````tab
tab: 1
**块内偏移：log16=4位；块号：log(64K/16)=12位；标记位：32-4-12=16位；先根据块号找到对应的cache行**
![|375](Images/Pasted%20image%2020241207114821.png)
tab: 2
**第二步：对比标记位**
![|375](Images/Pasted%20image%2020241207114953.png)
tab: 3
**第三步：确定有效位=1**
![|375](Images/Pasted%20image%2020241207115137.png)
tab: 4
**第四步：根据块内偏移找到对应的字节**
![|375](Images/Pasted%20image%2020241207115357.png)
tab: 5
**第四步详细内容**
![](Images/Pasted%20image%2020241207151819.png)
````
2. 全相连映射(随意放)
![](Images/Pasted%20image%2020241116113606.png)
只要有空闲行，就不会发生冲突，标志位长，比较电路成本太高
3. 组相联映射(可放到特定分组)
![](Images/Pasted%20image%2020241116113926.png)
某按字节编址的计算机层次存储系统，地址位数为 32 位，缓存的大小为 1024 字节，缓存行大小为 8 字节，采用 2 路组相联的方式。索引的位数为 6 位，标记位为 23 位
块内地址 = $\log_28=3$ 位
缓存组数 = $\frac{1024B}{8B*2}=64$，对应 6 位
标记位 = 32 - 3 - 6 = 23 位

关联度：一个主存块映射到 Cache 中，可能存放的位置个数
	直接映射：关联度最低，为 1
	全相联映射：关联度最高，为 cache 行数
	N-路组相联映射：关联度居中，为 N
关联度越高，总的标记位数越多，额外空间开销越大
## 块替换策略
1. 直接映射
如果对应位置非空，替换
2. 全相联映射
Cache 完全满了才替换，需要在全局选择替换
3. 组相联映射
分组内满了才替换，需要在分组内选择替换

最近最少使用 LRU
	替换最近最少使用的块
FIFO
	替换最先被调入 Cache 的块
RAND
	随机选择一块替换
## 一致性保证
写命中（要写的单元已经在 Cache 中）：
1. 写直达(Write through)
- 写操作时数据既写入 Cache 又写入主存
- 使用写缓冲：在 CPU 写 Cache 的同时，也将信息写入写缓冲(FIFO 队列)，然后由存储控制器将写缓冲中的内容写入主存
- 强一致性保证，效率低，搭配写分配或非写分配
2. 拖后写/写回法(Write back)
- 写操作时只把数据写入 Cache 而不写入主存(dirty bit)，当 Cache 数据被替换出去时才写回主存
- 弱一致性保证，效率高，搭配写分配
	- 主动替换
	- 被动替换
- 通过监听总线上的访问操作来实现
写不命中（要写的单元不在 Cache 中）：
1. 写分配法
当 CPU 对 Cache 写不命中时，先在主存块中更新相应存储单元，然后分配一个 Cache 行，将更新后的主存块装入到分配的 Cache 行中
2. 非写分配法
当 CPU 对 Cache 写不命中时，只写入主存，不调入 Cache
## Cache 缺失原因
1. 必然缺失
	- 开机或者是进程切换
	- 首次访问数据块
	  策略：预取
2. 容量缺失
	- 活动数据集超出了 Cache 的大小
	  策略：增加 Cache 容量
3. 冲突缺失
	- 多个内存块映射到同一 Cache 块
	- 某一 Cache 组块已满，但空闲的 Cache 块在其他组
	  策略：增加 Cache 容量 / 增加相联的组数
4. 无效缺失
	- 其他进程修改了主存数据
经验总结：容量为 N，采用直接映射方式 Cache 的缺失率和容量为 N/2、采用 2 路组相联映射方式 Cache 的缺失率相当
![|500](Images/Pasted%20image%2020241116153120.png)
## 提高命中率
1. 采用两级或更多级 cache 来提高命中率
2. 将 Cache 分解为指令 Cache 和数据 Cache
Cache 接入系统的体系结构
![|500](Images/Pasted%20image%2020241116153411.png)
![|500](Images/Pasted%20image%2020241116153443.png)
## 习题
假定计算机系统有一个容量为 32KB 的主存，且有一个 4KB 的 4 路组相联Cache，主存和 Cache 之间的数据交换块的大小为 64B。假定 Cache 开始为空，处理器顺序地从存储单元 0、1、…、4351 中取一个 Byte，一共重复 10 次。设 Cache 比主存快 10 倍。采用采用 LRU 算法。试分析 Cache 的结构和主存地址的划分。说明采用 Cache 后速度提高了多少？
>[!note] 
>块大小 64B，块内偏移 6 位
>
>Cache 行共 $\frac{4KB}{64B}=64$ 行，每 4 行为一组，共 $\frac{64}{4}=16$ 组，索引位 4 位
>
>总物理地址：$\log_232K=15$ 位，标记位 15-4-6=5 位
>![](Images/Pasted%20image%2020241207194837.png)
>
>依次从 0~4351 地址取，当从 0 地址取时，cache 不命中，取一个 64B 的块到 Cache 中，则随后地址 1~63 都将命中
>
>4352B/64B = 68 块，所以一轮循环会多 4 块
>![](Images/Pasted%20image%2020241207200406.png)
>多的 4 块为 64、65、66、67 分别映射到 0~3 组，由于此时整个 Cache 已满，采用组内 LRU 替换，会将每组中的第 0 路替换掉(第 0 路最先装入 Cache)
>
>所以在第一轮循环，每个块的第一个字节都会未命中，其余都命中
>
>在第 2 轮循环，第 0 块根据 LRU 会替换第 0 组的第 1 路(因为此时第 0 路是第一轮循环中的块 64，是最后的块)，
# 内存管理
- 物理地址(PA)空间：物理内存的地址空间
- 逻辑地址(LA)空间：程序执行的地址空间
- 线性地址(虚拟地址)空间：虚拟内存的地址空间
逻辑地址+段式管理->虚拟地址(线性地址)
	在没有段式内存管理的情况下，逻辑地址和虚拟地址相同
虚拟地址+页式管理->物理地址
	在没有页式内存管理的情况下，逻辑地址和物理地址相同

虚拟内存可以作为外存的缓存，运行的程序直接用虚拟地址，不用关注具体放在物理内存还是外存
## 地址生成过程
（1）OS：建立逻辑地址和物理地址的映射关系表，同时确保每一个程序访问的地址空间是合法的（界限寄存器、基准寄存器：设置逻辑地址空间基准、界限），不能产生交叉干扰的情况
（2）当 CPU 要执行某条指令时，ALU 部件会发出请求指令（发送<font color="#ff0000">逻辑地址</font>）
（3）CPU 中的 MMU 部件会根据逻辑地址和物理地址的映射表，查找 ALU 发送来的逻辑地址对应的物理地址
（4）若没有，则会转移到内存中继续查找物理地址，若找到，则 CPU 的控制器会给主存发出请求，需要某物理地址的内容
（5）主存会将物理地址中的内容，通过总线传递到 CPU
（6）最后 CPU 拿到指令内容，开始执行
![|500](Images/Pasted%20image%2020241117214254.png)
## 连续内存分配
- 静态内存分配：编译时的内存分配
- 动态内存分配：运行时的内存分配
	- 显示分配：要求应用显示释放已分配的块，例如 malloc
	- 隐式分配：编译器/运行时库自动释放未使用的已分配的块
### 最先匹配
![|500](Images/Pasted%20image%2020241117232334.png)
空闲分区列表按**地址顺序**排序
释放分区时，检查是否可与临近的空闲分区合并
优点：简单，在高地址空间有大块的空闲分区
缺点：外部碎片，分配大块时较慢(顺序查找)
### 最佳匹配
![|500](Images/Pasted%20image%2020241117232557.png)
空闲分区列表按**大小**排序
释放分区时，同上
优点：大部分分配的尺寸较小时，效果很好
缺点：外部碎片，释放分区较慢(找临近空闲分区麻烦)，容易产生很多无用的小碎片
### 最差匹配
![|500](Images/Pasted%20image%2020241117233048.png)
空闲分区列表按**由大到小**排序
释放时，进行可能的合并，并调整空闲分区列表顺序
优点：
	中等大小分配较多时，效果最好
	避免出现太多的小碎片
缺点：
	释放分区较慢
	外部碎片
	容易破坏大的空闲分区，因此后续难以分配大的分区
## 碎片整理
- 碎片紧凑：
	- 通过移动分配给进程的内存分区，以合并外部碎片
	- 要求所有的程序可动态重定位
- 分区对换：
	- 通过抢占并回收处于等待状态进程的分区，以增大可用内存空间
## 伙伴系统
整个可分配分区大小为 $2^U$
待分配分区大小为 $2^{U-1}<s\leq 2^U$，将整块分配给应用
由小到大在空闲块中找最小可用块
如果空闲块过大，对可用空闲块进行二等分，直到得到合适可用空闲块
![|800](Images/Pasted%20image%2020241117234528.png)
合并条件：大小相同，低地址空闲块起始地址为 $2^k$
## 非连续内存分配
![|500](Images/Pasted%20image%2020241117235131.png)
### 段式管理地址转换
![|500](Images/Pasted%20image%2020241116154404.png)
段基址寄存器+段界寄存器(每段对应一个)
在<font color="#ff0000">内存中</font>保存段表，段表项包含段基址和段长
![|500](Images/Pasted%20image%2020241118174009.png)
PPT 中将各个段基址寄存器的值画在了一起
![|500](Images/Pasted%20image%2020241118090104.png)
### 页式管理地址转换
![|500](Images/Pasted%20image%2020241116154751.png)
页帧：把物理地址空间划分为大小相同的基本分配单位
![](Images/Pasted%20image%2020241118090751.png)
共有 $2^F$ 个帧，每帧有 $2^S$ 个字节
$物理地址 = f \times 2^S + o$
物理地址空间范围 $(0+0)\sim(2^F-1+2^S-1)$

页面：把逻辑地址空间划分为大小相同的基本分配单位
页帧和页面大小相同
页内偏移 = 帧内偏移
通常：页号大小 $\neq$ 帧号大小
![|330](Images/Pasted%20image%2020241118091435.png)
共有 $2^P$ 个页，每页有 $2^S$ 个字节
页面->页帧：
- 逻辑地址->物理地址
- 硬件机制：页表/MMU/TLB
- <font color="#ff0000">不是</font>所有的页都有对应的帧
![|500](Images/Pasted%20image%2020241118092144.png)
每个进程都有一个页表：
- 每个页面对应一个页表项
- 随进程运行状态而<font color="#ff0000">动态变化</font>
- 页表基址寄存器(PTBR)
![](Images/Pasted%20image%2020241118100352.png)
页表的性能问题：
- 访问一个内存单元需要 2 次内存访问
	- 第一次访问：获取页表项
	- 第二次访问：访问数据
- 页表可能非常大
#### 多级页表
![|500](Images/Pasted%20image%2020241118102429.png)
二级页表可以使某些<font color="#00b0f0">不存在映射关系的页表项不再占用内存</font>。假设一级页表的某页表项的驻留位为0，则它指向的二级页表不需要存储在内存中，相比之下，一级页表中，**无论页表项是否存在映射关系**，页表项都存储在页表中，占用了内存。所以，二级页表与一级页表相比，节省了大量空间。
#### 页寄存器
每个<font color="#00b0f0">页帧</font>和一个页寄存器关联，寄存器内容包括：
- 使用位：此<font color="#95b3d7">帧</font>是否被进程占用
- 占用页号：对应的<font color="#ffc000">页号</font> p
- 保护位
![|500](Images/Pasted%20image%2020241118104737.png)
缺点：
- CPU 知道的是页号，而页寄存器的索引是帧号，不使用关联存储器，只能顺序搜索。引入关联存储器可以并行查找页号对应的索引帧号，但硬件逻辑复杂。
优点：
- 页寄存器的容量只与物理地址空间的大小相关，与逻辑地址空间的大小无关，用页寄存器储存的页表相对于物理内存很小
哈希查找是替代关联存储器的另一种实现方式：对逻辑地址进行 Hash 映射，以减少搜索范围
用 TLB 缓存页表项后的页寄存器搜索步骤：
1. 对逻辑地址进行 Hash 变换得到帧号
2. 在快表中根据帧号查找对应页表项
3. 有冲突时遍历冲突项链表
4. 查找失败时，产生异常
#### 反置页表
基于页寄存器实现，加入 PID 做 Hash
![|500](Images/Pasted%20image%2020241118110729.png)
![|500](Images/Pasted%20image%2020241118111159.png)
### 段页式存储管理
![|500](Images/Pasted%20image%2020241118111721.png)
一个段对应多个页，由段表得到对应页表的基址
![|500](Images/Pasted%20image%2020241118111809.png)
## TLB
TLB 使用关联存储实现，也是 Cache，和 CPU Cache 一样，TLB 也分为数据 TLB 和指令 TLB，也有多种映射方式，也存在多层级
TLB 缓存的是<font color="#ff0000">在 Cache 中的页表项组成的页表</font>
![|500](Images/Pasted%20image%2020241116161919.png)
![|500](Images/Pasted%20image%2020241118101111.png)
![|500](Images/Pasted%20image%2020241116162809.png)
Miss1 -> TLB 缺失将产生异常：
- 流水线停止
- 通知 OS
- 查内存页表(也可能 TLB 和页表同步查询)
- 若发生 hit2，<font color="#ff0000">将页表项写入 TLB</font>
- 返回到用户程序
- 重新访问
![|500](Images/Pasted%20image%2020241116173444.png)
![|200](Images/Pasted%20image%2020241116171659.png)
![|500](Images/Pasted%20image%2020241116165148.png)
![](Images/Pasted%20image%2020241116172808.png)
![](Images/Pasted%20image%2020241116172722.png)
进程切换对 TLB 的处理
<font color="#ff0000">在上下文切换时</font>，清空(flush) TLB，但会导致新进程触发 TLB 未命中，如果频繁切换进程，开销会很高
加上 ASID(类似 PID)，不同进程可以共享 TLB
进程切换涉及到TLB的失效及更新，线程不涉及，所以进程切换代价大
## 虚拟存储
内存不够用解决方法：
- 函数覆盖：应用程序以函数/模块为单位手动换入换出内存
![|500](Images/Pasted%20image%2020241118113307.png)
- 程序交换：OS 以程序为单位自动换入换出内存
![](Images/Pasted%20image%2020241118152203.png)
程序换入时不一定在原处，采用动态地址映射
交换区大小：存放所有用户进程的所有内存映像的拷贝

- 虚拟存储：OS 以页为单元自动换入换出内存
虚拟存储 = 内存+外存
- 原理：
	- 装载程序时：只将当前指令执行需要的部分页面或段装入内存
	- 指令执行中：如果需要的指令或数据不在内存，处理器通知 OS 将相应的页面或段调入内存
	- OS 将内存中暂时不用的页面或段保存到外存
- 支持技术
	- 硬件：MMU/TLB/页表——页式或段式存储中的硬件地址转换机制、硬件异常
	- 软件：OS——内存中建立页表或段表，管理内存和外存间页面或段的换入和换出
### 虚拟页式存储
在页式存储管理的基础上，增加请求调页和页面置换
![|500](Images/Pasted%20image%2020241118153709.png)
![|500](Images/Pasted%20image%2020241118153926.png)
访问位(替换位、引用位)：表示该页是否被访问过
修改位：表示在内存中的该页是否被修改过
有效位(存在位、驻留位)：表示该页是否在内存中
保护位：表示该页的允许访问方式
在何处保存未被映射的页
- 交换空间(磁盘/文件形态)：采用特殊格式存储未被映射的页面
- 磁盘上的文件(代码或数据)
性能：
p：缺页率
q：写回概率(淘汰一个页面到磁盘)
有效存储访问时间 EAT = 访存时间 \* (1-p) + 缺页异常处理时间
缺页异常处理时间 = 磁盘访问时间 \* p \* (1+q)
### 页面置换算法
页面锁定/常驻内存：必须常驻内存的逻辑页面
- OS 的关键部分
- 要求响应速度的代码和数据
- 页表中的锁定标志位
#### 局部页面置换算法
置换页面的选择范围仅限于当前进程占用的物理页面内
- OPT：置换在未来最长时间不访问的页面
缺页最少，实际系统中无法实现
![|500](Images/Pasted%20image%2020241118164614.png)
- FIFO 先进先出页面置换算法
置换在内存驻留时间最长的页面
![|500](Images/Pasted%20image%2020241118164801.png)
- LRU 最近最久未使用算法
置换最长时间没有被引用的页面
![|500](Images/Pasted%20image%2020241118165017.png)
可以用页面链表或活动页面栈实现
![|500](Images/Pasted%20image%2020241118165221.png)
- Clock 时钟置换算法
是 FIFO 和 LRU 的折中
在页表项中增加访问位，各页面组织成环形链表，指针指向最先调入的页面
![|500](Images/Pasted%20image%2020241118165826.png)
- 改进的 Clock 算法
增加修改位，修改位为 1 的页将会多一轮驻留机会
![|300](Images/Pasted%20image%2020241118175044.png)
![|500](Images/Pasted%20image%2020241118175127.png)
- LFU 最不常用页面置换算法
置换访问次数最少的页面
基础实现：每个页面设置一个访问计数，访问页面时，访问计数加 1，缺页时置换计数最小的页面
为避免出现开始频繁使用，但以后不使用的页面很难置换，定期右移计数
![|500](Images/Pasted%20image%2020241118175719.png)
#### Belady 现象
分配的物理页面数增加，缺页次数反而升高
![|500](Images/Pasted%20image%2020241118175855.png)
![|500](Images/Pasted%20image%2020241118175938.png)
对于未被访问的页面，Clock 和 LRU 和 FIFO 算法的表现一样
对于被访问的页面，Clock 不能记录准确访问顺序，而 LRU 可以
#### 全局页面置换算法
置换页面的选择范围是所有可换出的物理页面
局部页面置换算法没有考虑到<font color="#00b0f0">进程访存差异</font>，进程在不同阶段的内存需求是变化的
全局置换算法为进程分配<font color="#ff0000">可变数目</font>的物理页面数
![|500](Images/Pasted%20image%2020241118180653.png)
工作集：一个进程<font color="#ff0000">当前正在使用</font>的逻辑页面集合，可表示为二元函数 $W(t,\Delta)$
t：当前的执行时刻
$\Delta$：工作集窗口，一个定长的页面访问时间窗口
$W(t,\Delta)$：指在当前时刻 t <font color="#ff0000">前</font>的 $\Delta$ 时间窗口中的<font color="#ff0000">所有访问页面</font>所组成的集合
$|W(t,\Delta)|$：工作集的大小，即页面数量
![|500](Images/Pasted%20image%2020241118181454.png)
常驻集：在当前时刻，进程<font color="#ff0000">实际驻留</font>内存中的页面集合
工作集和常驻集的关系：
	工作集是进程在运行过程中<font color="#ff0000">固有的</font>性质
	常驻集取决于系统的分配和页面置换算法
缺页率和常驻集的关系
	常驻集 $\supset$ 工作集时，缺页较少
	工作集发生剧烈变动时，缺页较多
	进程常驻集大小达到一定数目后，缺页率也不会明显下降
- 工作集页面置换算法
换出不在工作集中的页面(并不一定在缺页的时候)
窗口大小 $\tau$：当前时刻前 $\tau$ 次内存访问的页集合构成工作集
![|500](Images/Pasted%20image%2020241118193001.png)
- 缺页率页面置换算法
缺页率：$\frac{缺页次数}{访存次数}$ 或缺页平均时间间隔的倒数
![|500](Images/Pasted%20image%2020241118193306.png)
访存时，设置引用位标志
缺页时，计算从上次缺页时间 $t_{last}$ 到现在 $t_{current}$ 的时间间隔
如果 $t_{current}-t_{last}>T$，则置换所有在 $[t_{last},t_{current}]$ 时间内没有被引用的页
如果 $t_{current}-t_{last}\leq T$，则增加缺失页到工作集
![|500](Images/Pasted%20image%2020241118193925.png)
抖动问题
抖动：
	进程物理页面太少，不能包含工作集
	造成大量缺页，频繁置换
产生抖动的原因：
	随着驻留内存的进程数目增加，分配给每个进程的物理页面数不断减少，缺页率不断上升
![](Images/Pasted%20image%2020241118194343.png)
## 习题
1. 引入虚拟内存的目的是提高内存的访问速度（×）
   是为了提高主存-辅存访问效率
2. 虚拟地址到物理地址的转换关系由软件来维护（×）
   由软件和硬件共同的维护的
3. 关于 TLB 的功能，以下描述正确的是？
   (A)TLB 把应用程序访问的数据缓存到 CPU 中
   (B)TLB 缺失后,能够在 L1 指令缓存中找到相应的内容
   (C)TLB 缺失之后会导致应用程序出错 
   (D)TLB 缓存虚拟地址到物理地址的映射关系 
   A 不对，缓存的是逻辑地址到物理地址的映射关系
   B 不对，不一定能在 L1Cache 中找到对应内容
   C 不对，TLB 缺失之后，页表可能命中
4. 虚拟存储系统可以加快磁盘的存取速度（×）
   不能加快磁盘的存取速度，只是因为局部性原理可以使得整个主存-辅存系统的速度接近内存，并且容量更大
5. 某机器采用按字节寻址的方式。30 位虚拟地址，28 位物理地址，一级页表，页面大小 16KB。快表的访问时间是 5ns，Cache 采用直接相连映射，大小 64KB，块大小 4B，一次 cache 命中访问时间 5ns
   虚拟页表脏位 1 位，有效位 1 位，问页表大小？
   >[!note]-
   > 页面大小 16KB，所以页内偏移有 14 位
   > 
   > 页帧位数 = 28(物理地址总位数) - 14 = 14 位
   > 
   > 页表项的位数 = 标记位+页帧数(物理页号) = 2 + 14 = 16 位（注意有时需要向上按字节取整）
   > 
   > 虚拟页号 = 30 - 14 = 16 位
   >
   > 虚拟页数 = 2^(16) = 64K 个，所以页表项也就有 64K 个
   > 
   > 页表大小 = 64K \* 16bit(页表项位数) = 64K \* 2B = 128KB
   
   cache 标志位、索引位、块内地址各多少位？
   >[!note]-
   > 块大小 4B，所以块内地址 log 4 = 2 位
   > 
   > cache 大小 64KB，每个块 4B，共 64KB/4B = 16K 个 cache 块
   > 
   > 索引位 = log 16K = 14 位
   > 
   > 标志位 = 28(物理地址) - 14 - 2 = 12 位

   系统进程切换时以下操作是否需要，说明原因
   a）清除 cache 有效位
	   不需要，cache 缓存了**物理地址**中的内容，进程切换时并不会直接导致缓存中的内容全部失效
   b）将已经调入快表清空
	  通常需要，每个进程有自己的页表，整个系统中只有一个快表，快表是页表的 cache，切换进程，页表变化，快表内容失效（但部分系统增加了硬件支持，实现跨上下文切换的 TLB 共享，例如在 TLB 中添加 ASID 字段）
	
	注意到快表访问和 cache 访问时间相同，能否修改访问方式，使 cache 和页表一同访问？
	  可以，将 cache 修改为通过虚拟地址查找，一旦发现 cache 中有对应的数据项，则无需页表查找的物理地址再去访存
	  cache 块内地址不变：2 位
	  索引位不变：14 位
	  标记位变化：30(虚拟地址) - 2 - 14 = 14 位
6. 以下说法正确的是？
   (A)缓存越大程序执行速度越快
   (B)TLB 也是一种缓存数据和指令的缓存器 
   (C)指令和数据采用不同的缓存可以提高流水线速度
   (D)缓存可以提高主存容量
   >[!note]-
   >A 选项，Cache 越大，虽然命中会提升，但是 Cache 查找的开销本身就会增大
   >B 选项，TLB 是缓存页表项的
   >C 选项，正确，指令 Cache 和数据 Cache 分离，防止 IF 段和 MEM 段结构冲突
   >D 选项，缓存只是主存一部分的拷贝,不会提高主存容量.

7. 给出一个指令序列，cache 容量是 1024B，循环 100 次，每次访问 3 和 3+1024 地址的内容，计算直接映射的命中率为？二路组相联的缓存命中率为？
   >[!note]
   >（1）直接映射情况
   >
   >cache 容量是 1024B，所以索引位+块内偏移=10 位
   >
   >访问 3 和 3+1024 对应的索引位和块内偏移一样(两个地址只有最高位不同，而标记位至少有 1 位)，所以 3 和 3+1024 两个地址总是映射到同一个 cache 块中，每次循环先访问 3->不命中，将地址 3 数据装入 cache 块，然后访问 3+1024->不命中，又替换成 3+1024 地址数据，导致一直不命中
   >
   >缓存命中率 = 0%
   >
   >（2）二路组相联情况
   >
   > 假设直接映射索引位有 x 位，说明 cache 分为了 $2^x$ 行，则二路组相联映射就有 $\frac{2^x}{2} = 2^{x-1}$ 组，所以二路组相联索引位有 x-1 位(标记位恰好多 1 位来区别同一组的不同块)
   > 
   > 故索引位+块内地址 = 9 位，同上 3 和 3+1024 总是映射到同一组中，组内有两块，第一次访问时不命中，之后全部命中
   > 
   > 缓存命中率 = 99%

8. 4 路组相联，2 路组相联，全相联缓存命中率最高的是？
   全相联映射
9. 在相同缓存容量，相同缓存行大小的情况下，全相联缓存命中率不比组相联低（×）
   比如 cache 有四行，访问 0,1,2,3,5,0,1,2,3,5,0,1,2…循环访问，LRU 替换算法，组相连映射命中率比全相连高
10. 一个 32 位按字节编址的计算机，数据缓存的缓存行的大小位为 8B，缓存行有 4 个，缓存状态初始为无效，现执行一个程序，依次访问 0x100，0x110，0x120，0x130，0x100，0x110，0x120，0x130，若为直接映射，命中次数为？若为全相联，采用 LRU 替换策略，命中次数为?
> [!note] 
>（1）直接映射
>块内地址 3 位，索引位 2 位
>![](Images/Pasted%20image%2020241207172352.png)
>（2）全相联映射
>索引位 0 位，块内地址 3 位，标记位 29 位
>
>访问 0x100、0x110、0x120、0x130 未命中，后续全命中
>
>一共命中 4 次

11. 软件管理高速缓存 Cache 与主存储器地址之间的映射关系（×）
12. 一台计算机虚拟空间 8KB，物理空间 4KB，采用二级页表的方式组织内存，页表项是 2B，页目录项 1B，页表大小 32B，求进程页面大小？
    ![](Images/Pasted%20image%2020241207181116.png)

# IO
I/O 接口(I/O 控制器)的功能：
1. 数据缓冲
   实现主机和外设工作速度的匹配
2. 错误或状态检测
   一类是设备电路故障或异常情况
   另一类是数据传输错误
3. 控制和定时
   接受从控制总线发来的控制信号、时钟信号
4. 数据格式转换
   串-并、并-串等格式转换
![|500](Images/Pasted%20image%2020241116220510.png)
I/O 端口是指 I/O 控制器中 CPU 可访问的寄存器，对 I/O 设备的寻址就是对 I/O 端口的访问
![|500](Images/Pasted%20image%2020241116220742.png)
独立编址：
	优点：不占用内存空间，使用 I/O 指令，译码电路简单
	缺点：只能用专门的 I/O 指令，访问端口的方法少于访问存储器
统一编址：
	优点：可以利用存储器的寻址方式来寻址 I/O 端口
	缺点：I/O 端口占用了存储空间，地址编码长，速度较慢
同步与异步 I/O
![|500](Images/Pasted%20image%2020241118204030.png)
![|500](Images/Pasted%20image%2020241118204100.png) 
![|500](Images/Pasted%20image%2020241118204203.png)
![](Images/Pasted%20image%2020241122191241.png)
1. 阻塞 I/O：在用户进程发出 I/O 系统调用后，进程会<font color="#ff0000">等待</font>该 I/O 操作完成，而使得进程的其他操作无法执行。
2. 非阻塞 I/O：在用户进程发出 I/O 系统调用后，如果数据没准备好，该 I/O 操作会立即返回，之后进程可以进行其他操作；如果数据准备好了，用户进程会通过系统调用完成数据拷贝并接着进行数据处理。
3. 多路复用 I/O：将多个非阻塞 I/O 请求的轮询操作<font color="#ff0000">合并</font>到一个select 或 epoll 系统调用中进行。
4. 信号驱动 I/O：利用信号机制完成从内核到应用进程的事件通知。
5. 异步 I/O：不会导致请求进程阻塞。

**数据传送控制方式**
## 程序直接控制
   CPU 直接使用输入/输出指令来控制外部设备
- CPU 方：查询接口状态(循环等待)->直到外设已经接收到该字符->读字符
- 外设方：往接口数据缓冲中送字符->处理完后，置状态寄存器->等待下一个字符  
**特点**
- 成本低
- 效率低
- 严重占用 CPU 资源
## 程序中断
   外部设备请求，CPU 响应，CPU 与外设并行工作
- 外部设备发起请求->CPU 暂停正在执行的程序进行响应->处理完成后继续执行原来的程序
- 提高 CPU 的效率
- 可以同时管理多个外部设备
![|500](Images/Pasted%20image%2020241122190427.png)
**特点**
- 对 I/O 请求慢：每传送一个数据都要等待外设的中断请求，并由额外的中断开销，不能及时响应 I/O 请求
- 数据传送速度慢：数据传送由软件完成(由 CPU 执行相应的中断服务程序来完成)
- 对 CPU 干扰较大
## DMA (直接存储访问)
   专用输入/输出控制器
- 基本思想：在高速外设和主存间之间传送数据，由专门硬件(DMA 接口)控制总线进行传输
- 适用场合：高速设备、成批数据交换，且数据间间隔时间短，一旦启动，数据连续读写
- 主存储器需要支持成组传送
- 采用“请求-响应”方式
	- 每当高速设备准备好数据，就进行一次“DMA 请求”，DMA 控制器接受到 DMA 请求后，申请总线使用权
	- DMA 控制器的总线使用优先级比 CPU 高
- 与中断控制方式结合使用
	- DMA 传送前，“寻道、旋转”等操作结束时，通过“中断”告知 CPU
	- 在 DMA 控制器控制总线进行数据传送时，<font color="#ff0000">CPU 执行其他程序</font>
	- DMA 传送结束时，要通过“DMA 结束中断”告知 CPU
例如：
![|305](Images/Pasted%20image%2020241116235732.png)
**DMA 工作方式**
DMA 接口和 CPU 共享主存，所以可能出现两者争用主存的现象，为协调两者，通常采用如下方式：
- 独占总线方式(成组传送)
  DMA 传输时，CPU 脱离总线，停止访问主存，直到 DMA 传送一块数据结束
	- 优点：控制简单
	- 缺点：CPU 工作受影响
	改进：
	- 在 DMA 接口中引入缓冲器，I/O 设备->缓冲器->主存
	- 采用周期窃取法
- 周期窃取方式(单字传送)
  DMA 传输时，CPU 让出一个总线事务周期，由 DMA 控制总线来访问主存，传送完一个数据后立即释放总线
![|500](Images/Pasted%20image%2020241117001446.png)
适用于 I/O 设备的读写周期大于主存周期
  - 优点：既能及时响应 I/O 请求，又能较好的发挥 CPU 和主存效率
  - 缺点：每次 DMA 访存都要申请占用释放总线，会增加传输开销
![|500](Images/Pasted%20image%2020241117002028.png)
- 交替分时访问法
  每个存储周期分成两个时间片，一个给 CPU，一个给 DMA，这样在每个存储周期内，CPU 和 DMA 都可访问存储器
适用于 CPU 工作周期比主存存取周期更长的情况，不需要总线使用权的申请和释放
![|500](Images/Pasted%20image%2020241117002323.png)
DMA 控制器组成
![|500](Images/Pasted%20image%2020241117003202.png)
![|500](Images/Pasted%20image%2020241117003628.png)
DMA 方式的问题：
- 虚拟地址和实地址
	- DMA 采用实地址：虚拟地址连续，但实地址不连续，需要限制所有 DMA 传送在一个页面进行
	- 采用虚拟地址：DMA 进行虚实地址转换
- Cache 一致性
DMA 特点
- 与设备一对一服务
  多 DMA 控制器同时工作可能发生冲突
- 对 CPU 打扰适中
- 无法适用大量高速设备管理
## 通道
I/O 通道是 OS 中代替 CPU 管理控制外设的独立部件，是一种能执行有限 I/O 指令集合——通道命令的 I/O 处理机
- 一对多的连接关系
- 适应不同速度、不同种类的外部设备、可并行工作
![|500](Images/Pasted%20image%2020241117005136.png)
通道类型：
- 字节多路通道
简单的共享通道，分时处理，面向多台低、中速字符设备
- 选择通道
选择一台外设独占整个通道，以成组传送方式传送数据块，效率高，适合快速设备
- 数组多路通道
上两种方式的结合，效率高，控制复杂
## 外围处理机
输入输出处理机方式是通道方式的进一步发展，有两种输入输出处理机系统结构
1. 通道型处理机(IOP)
   与通道方式一样，也通过执行通道程序对外设进行控制，能和 CPU 并行工作
   区别：IOP 功能更强，有专用指令系统；通道方式下，通道程序存于和 CPU 公用的主存中，而 IOP 有单独的存储器，且可访问系统内存
2. 外围处理机(PPU)
   - 在大型计算机系统中，选用通用计算机担任 PPU
   - 独立完成输入/输出功能
   - 通过通道方式和主机进行交互
# 总线
## 相关概念
总线：多个部件之间进行数据传送的共享通道
总线主设备：有能力控制总线，发起总线事物
总线从设备：响应主设备请求
总线通信协议：定义总线传输中的事件顺序和时序要求
异步总线传输：控制信号(请求，应答)作为总控信号
同步总线传输：使用共同的时钟信号

性能指标：
总线带宽=总线宽度 \* 总线时钟频率 / 完成一次数据传送所用的时钟周期数

![](Images/Pasted%20image%2020241117154134.png)
<font color="#ff0000">总线事务</font>包含两个部分：
- 发起命令（和地址）
- 传输数据
主设备是总线事务的发起者：
- 发出命令（和地址）
从设备是总线事务的响应者：
- 若主设备发出的是读命令，则将数据发送到主设备
- 否则，接收主设备发来的写入数据

**单总线计算机：主板总线**
![|725](Images/Pasted%20image%2020241117151856.png)
优点：简单、成本低
缺点：速度慢，总线将成为系统瓶颈
**双总线系统**
![](Images/Pasted%20image%2020241117152034.png)
- 输入/输出总线通过适配器和处理器-主存总线相连
	- 处理器-主存总线：主要用于处理器和主存储器之间的通信
	- 输入/输出总线：为输入/输出设备提供信息
**三总线系统**
![](Images/Pasted%20image%2020241117152246.png)
主板总线连接到处理器-主存总线
- I/O 总线连接到主板总线
- 处理器-主存总线：主要用于处理器和主存之间数据交换
优点：大大减少处理器-主存总线负载

总线的一般组成：
- 控制线：
	- 标记总线事务的开始和结束
	- 指明数据线上传输信息的类型
- 数据线：在源设备和目标设备间传送信息
	- 数据和地址
	- 复杂的命令
- 地址线：给出源数据或目的数据所在的主存单元或 I/O 模块地址
	- 单向，总是由 CPU 将地址信息送到地址线，随后传送给 CPU 要访问的主存储器或 I/O
有些总线没有单独的地址线，地址信息通过数据线来传送，称为数据线和地址线复用
## 总线仲裁
仲裁：获得总线使用权
### 集中仲裁
菊链仲裁：所有设备共用一个总线请求信号
![](Images/Pasted%20image%2020241117155105.png)
优点：简单
缺点：
- 无法保证公平性
	- 低优先级设备可能得不到总线使用权
- 总线授权信号的逐级传递限制了申请总线的速度

集中平行仲裁：通过集中的仲裁器进行
![|500](Images/Pasted%20image%2020241117160747.png)
### 分布仲裁
通过自我选择进行分布式仲裁：
  - 每个要使用总线的设备将自己的<font color="#ff0000">标识</font>放在总线上
![](Images/Pasted%20image%2020241117161205.png)
碰撞检测：
  - 以太网
## 总线定时方式
同步总线：
- 控制线中包含有一根时钟信号线
- 传输协议根据时钟信号制定：
	例如：主设备提出总线请求后 5 个时钟周期，获得能否使用总线的信号
- 优点：逻辑简单、高速
- 缺点：
	- 总线上所有设备必须按时钟频率工作
	- 为防止时钟信号扭曲，高速工作时，总线距离必须足够短
![|500](Images/Pasted%20image%2020241117164906.png)
异步总线：
- 不使用统一的时钟
- 可适应设备的不同速度
- 不用担心时钟信号扭曲，距离可较长
- 使用握手协议
![|500](Images/Pasted%20image%2020241117164658.png)
7 次握手，全互锁
## 增加总线带宽
采用成组传送方式
- 一个总线事务传送多个数据
- 每次只需要在开始的时候传送一个地址
- 直到数据传送完毕才释放总线
- 代价
	- 复杂度提高
	- 延长后续总线请求的等待时间
多主设备总线提高事务数量
- 仲裁重叠
	- 在当前事务时，为下一总线事务进行仲裁
- 总线占用
	- 在没有其他主设备请求总线的情况下，某主设备一直占用总线，完成多个总线事务
- 地址、数据传送重叠
## 习题
1. 相对程序直接控制方式，DMA 可以提高硬盘到内存的装入速度（√）
   程序直接控制的方式，IO 设备和 CPU 交换信息存储在寄存器当中，不可能大量的和磁盘交换信息。而 DMA 方式,是 IO 设备成批地直接和主存交换信息
2. DMA 设备不可以独占使用内存总线周期（×）
   DMA 使用总线有独占总线和周期窃取
3. 以下关于通过 DMA 方式进行数据传输的描述，错误的是？
   A.DMA 用于数据的快速传输,可用来代替中断方式
   B.DMA 控制器与 CPU 交替使用总线
   C.DMA 可以直接访问主存
   D.数据传输过程由 DMA 自行控制
   A 错误，DMA 无法代替中断，甚至本身 DMA 的整个过程也需要利用中断
   B 正确，DMA 可以独占总线也可以周期窃取，但是即便是独占总线，在更长的时间的尺度上看 DMA 和 CPU 仍然是分时复用总线的。
   C，D 是 DMA 特点，正确
4. 对于机械硬盘，读取顺序存储的文件比随机存储的文件快(√)
   机械硬盘有寻道时间
5. 一台计算机显示器的分辨率为 800\*600，使用 RGB 颜色，每个颜色使用 1 个字节表达，帧率为 50Hz，显示器的总带宽的 80%用于刷新屏幕，则需要的显存带宽至少为？
   刷新带宽：800×600×24(RGB)×50b/s=576000000b/s=576Mb/s 
   显存带宽：576Mb/s×100/80=720Mb/s
   显存带宽=分辨率×每个像素点的颜色深度×刷新速率÷刷新时间所占的比率
6. IO 端口和主存可以统一编址（√）
7. 磁盘10000 转每分钟，传输数据 20MB/s，7ms 平均寻道时间，控制器延迟 0.3ms，读取 4KB 扇区数据需要多少时间？
   寻找扇区：$\frac{60}{10000}*0.5=0.003s=3ms$
   传输数据时间：$\frac{4*1024}{20*10^6}=0.2048ms$
   一共约为 7+0.3+3+0.2 = 10.5ms
8. 下面总线的说法正确的是？
   (A)并行总线速度大于串行
   (B)异步总线速度大于同步
   (C)单总线速度大于双总线
   (D)以上说法均错误
   A 不对，在高频率的情况下串行总线比并行总线更快
   B 说反了，同步总线速度大于异步
   C 说反了，双总线速度大于单总线速度
9. 一个 32 位的总线系统，时钟频率 200MHZ，2 个时钟周期传完一次，总线的带宽是？
   4B \* 200Mhz / 2 = 400MB/s
