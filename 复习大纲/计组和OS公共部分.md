# 异常和中断
## 异常
异常：来自 CPU 内部，硬件打断，系统调用以及其他打断程序正常运行流程的事件
中断：异步发生，来自外部设备，不是由专门的指令造成的，而是通过引脚发送信号并将异常号(标识引起中断的设备)放在系统总线上来触发中断
![|500](Images/Pasted%20image%2020241113181120.png)
若异常/中断处理程序能解决问题，则回到第 i 条指令或第 i+1 条指令继续执行
若是不可恢复的致命错误，则终止用户进程，通常具体处理过程全部由 OS 软件完成
各类异常发生的流水段不同，在每条指令执行结束时，会检测有没有中断请求
- IF 检出：无效指令地址
- ID 检出：无效指令、除数为 0
- EXE 检出：溢出，无效数据地址(lw、sw 指令)
- MEM 检出：对只读区域进行写操作的异常等
相关寄存器：
- 协处理器：处理器的一个<font color="#ff0000">可选</font>部件，负责处理指令集的某个扩展
- CP0：MIPS 的系统控制协处理器，用于处理难以用常规指令解决的问题，CPU 配置，Cache 控制，异常、中断控制、存储管理控制等，包含一系列寄存器
- SR(Status Register)状态寄存器：
	 EXL 段：异常级别，进入内核态，禁止中断
- Cause：导致中断或异常的原因
	  BD 段：是否在延迟槽中
	  IP 段：中断源
	  ExcCode：异常代码
- EPC(Exception Program Counter)异常程序计数器：异常/中断结束后从哪里开始重新执行
	  多周期 CPU：
		  - 中断：指令执行完成后检查中断源，EPC=PC
		  - 异常：指令执行错误后，EPC=上一条指令的地址
	 指令流水 CPU
		 *精确异常*
- BadVaddr Register：访存错误发生时虚拟地址
	  当内存访问出错时保护
	  可用于后续对 TLB 的维护
- 精确异常：在处理异常时，产生异常的位置之前的命令都执行完毕，异常受害指令和其之后的好像从来没有开始一样(异常结束后重新执行，这些指令的行为和异常没有发生时完全一样)，当异常是精确异常时，处理异常的软件就可以忽略 CPU 实现的时序影响。
MIPS 异常处理流程：
1. 保存断点和程序状态：设置 EPC 指向重新开始的地址
   - PC->堆栈或 EPC
   - PSWR(PSW 寄存器，存放程序状态的寄存器)->堆栈或 EPSWR
2. 关中断：设置 SR(EXL)位，强制 CPU 进入内核态，并禁用中断
3. 保存异常原因：设置 Cause 寄存器，在地址异常时，BadVAddr 也要设置
   - 软件识别(MIPS)：OS 使用一个统一的异常处理程序查询 Cause
   - 硬件识别(向量中断 x86)：用硬件查询电路识别异常，得到<font color="#ff0000">中断类型号</font>，到<font color="#ff0000">中断向量表</font>中读取对应的中断服务程序<font color="#ff0000">入口</font>地址
4. 从异常入口点取指令，<font color="#ff0000">之后的事情交给软件处理</font>
5. 保存现场：通过 k0 和 k1 寄存器引用一段可以<font color="#ff0000">保存其他寄存器</font>的内部空间来实现
6. 读取异常原因，识别中断源：区分不同的异常，Cause 寄存器的 ExcCode 域
7. 构造异常处理内部空间：异常处理程序可能由高级语言编写，需要保留通用寄存器，构造堆、栈存储区
8. 处理异常
9. 恢复现场：恢复寄存器，清零 Cause 寄存器
10. 恢复断点：ERET 指令返回 EPC 指向的地址
11. 开中断：ERET 指令复位 SR(EXL)

异常嵌套：嵌套异常的服务程序必须用一部分主存空间来保存寄存器的值，使用的数据结构叫异常帧，多个嵌套异常的异常帧通常保存在栈中

MIPS 中断控制设计：
- 在中断发生时，如果指令已经完成了 MEM 段的操作，则保证该指令执行完毕
- 否则，丢弃流水线上这条指令的工作

磁盘访问过程：对磁盘的访问总是由缺页引起的
1. CPU 给出地址，需要访问某存储单元
2. 进行 TLB 查找和 cache 查找
3. TLB 查找后声明没有找到
4. 停止并行查找，并通知 OS 处理
5. OS 检查页表，发现缺页
6. OS 从主存中选择一页准备换出
	1. 若换出的页是脏页，需要将其写回磁盘存储
	2. OS 申请 I/O 总线
	3. 获得批准后，发送写命令给 I/O 设备(磁盘)，紧跟着传送需要写回的页的全部数据
	4. I/O 控制器发现发给自己的写命令，加入到握手协议，并接受数据
	5. 根据数据要写入的地址，读/写头移动到正确的柱面，同时将数据接受到缓冲区
	6. 寻道结束后，等待相应的扇区旋转到磁头下，将数据写入扇区中
	7. 在写入数据间隙，计算校验码并写入扇区中
7. OS 继续申请总线(如果还保持总线控制权，则不必申请)
8. 得到授权后，向磁盘发出读命令
9. 然后，磁盘识别地址，并转换为相应的地址段
10. 寻道，将读/写头移动到指定位置
11. 从指定扇区中读取数据，并进行校验
12. 磁盘申请 I/O 总线
13. 得到授权后，将数据通过总线送到内存
## 中断
相关概念：
- 中断源
	外中断：I/O 设备等
	异常(内中断)：处理器硬件故障、程序“出错”，Trap
	中断触发器
	中断状态寄存器
- 中断请求
	中断源设备设置中断触发器
		每个中断源有 1 个中断触发器
		同时可设置 1 个中断屏蔽触发器
- 中断响应
	响应条件
		允许中断、当前指令结束、优先级
	响应实现
		硬件实现的中断隐指令，保存断点
![](Images/Pasted%20image%2020241116224350.png)

# RAID
数据条带化：把一段连续的数据分割成相同大小的数据块，并将其分别写入到阵列中的不同磁盘上，使得多进程可以并发访问
## RAID0
没有冗余，可靠性差，数据条带化
![|500](Images/Pasted%20image%2020241114111702.png)
如果 I/O 请求访问不同盘上的数据，可以并行发送
## RAID1
镜像盘实现 1：1 冗余，没有数据条带化
![|300](Images/Pasted%20image%2020241114154304.jpg)
写：并行写，受限于写的慢的盘，性能稍微下降
读：提高 2 倍，虽然没有数据条带化，但考虑第一块提供 Block1，第二块提供 Block2
检错：直接从镜像盘恢复
可靠性高，成本高
## RAID2
![|500](Images/Pasted%20image%2020241114112532.png)
工作单位是字/字节
驱动器严格同步
用海明码生成多个冗余校验盘，实现一位纠错，两位检错
读：操作性能提高（多盘并行）
写：同时写数据盘和校验盘
## RAID3
![|500](Images/Pasted%20image%2020241114113219.png)
工作单位是字/字节
驱动器严格同步
是 RAID2 的简化版本，只对每个字计算一个奇偶校验位
读：操作性能提高（多盘并行）
写：同时写数据盘和校验盘
## RAID4
![|500](Images/Pasted%20image%2020241114161803.png)
独立访问
和 RAID0 类似，但和 RAID2、3 区别在于按块校验而不是按位校验
每个磁盘的操作独立进行，可以同时响应多个 I/O 请求
对盘上部分字节数据出错的纠错性能很差
校验盘负载很大
## RAID5
![|500](Images/Pasted%20image%2020241114162619.png)
独立访问
将校验位循环均匀分布到所有的驱动器上
## RAID6
![|500](Images/Pasted%20image%2020241114164202.png)
独立访问
PA：数据块 A 的校验值
P0：第 0 条块的校验值
采用双维块奇偶校验，允许双盘出错
应用于数据绝对不能出错的场合
## RAID7
![|500](Images/Pasted%20image%2020241114164750.jpg)
自身就带有实时操作系统和用于存储管理的软件工具，可完全独立于主机运行
有两个独立的 cache 双工运行，在 Cache 中完成校验
## RAID10
即 RAID1+0
![](Images/Pasted%20image%2020241114112314.png)
# Cache
- 用高速的静态存储器实现
- 完全硬件管理，对程序员透明
块(行)：数据交换的最小单位
![](Images/Pasted%20image%2020241116152605.png)
V：有效位
M：脏位
失效损失：替换较高层次数据块的时间+将该块交付给处理器的时间
平均访问时间：命中率 \* 命中时间 + (1-命中率) \* 失效损失
## 映射方式
1. 直接映射(只能放固定位置)
![](Images/Pasted%20image%2020241116111947.png)
利用率低，命中率低，效率较低
2. 全相连映射(随意放)
![](Images/Pasted%20image%2020241116113606.png)
只要有空闲行，就不会发生冲突，标志位长，比较电路成本太高
3. 组相联映射(可放到特定分组)
![](Images/Pasted%20image%2020241116113926.png)
## 块替换策略
1. 直接映射
如果对应位置非空，替换
2. 全相联映射
Cache 完全满了才替换，需要在全局选择替换
3. 组相联映射
分组内满了才替换，需要在分组内选择替换

最近最少使用 LRU

FIFO
替换最先被调入 Cache 的块
RAND
随机选择一块替换
## 一致性保证
写命中：
1. 写直达(Write through)
- 写操作时数据既写入 Cache 又写入主存
- 写缓冲：在 CPU 写 Cache 的同时，也将信息写入写缓冲(FIFO 队列)，然后由存储控制器将写缓冲中的内容写入主存
- 强一致性保证，效率低
	- 写分配法
	- 非写分配
2. 拖后写/写回法(Write back)
- 写操作时只把数据写入 Cache 而不写入主存，当 Cache 数据被替换出去时才写回主存
- 弱一致性保证，效率高
	- 主动替换
	- 被动替换
- 通过监听总线上的访问操作来实现
写不命中：
1. 写分配法
当 CPU 对 Cache 写不命中时，先在主存块中更新相应存储单元，然后分配一个 Cache 行，将更新后的主存块装入到分配的 Cache 行中
2. 非写分配法
当 CPU 对 Cache 写不命中时，只写入主存，不调入 Cache
## Cache 缺失原因
1. 必然缺失
	- 开机或者是进程切换
	- 首次访问数据块
	  策略：预取
2. 容量缺失
	- 活动数据集超出了 Cache 的大小
	  策略：增加 Cache 容量
3. 冲突缺失
	- 多个内存块映射到同一 Cache 块
	- 某一 Cache 组块已满，但空闲的 Cache 块在其他组
	  策略：增加 Cache 容量 / 增加相联的组数
4. 无效缺失
	- 其他进程修改了主存数据
经验总结：容量为 N，采用直接映射方式 Cache 的缺失率和容量为 N/2、采用 2 路组相联映射方式 Cache 的缺失率相当
![|500](Images/Pasted%20image%2020241116153120.png)
## 提高命中率
1. 采用两级或更多级 cache 来提高命中率
2. 将 Cache 分解为指令 Cache 和数据 Cache
Cache 接入系统的体系结构
![|500](Images/Pasted%20image%2020241116153411.png)
![|500](Images/Pasted%20image%2020241116153443.png)
# 虚拟存储器
- 物理地址(PA)空间：物理内存的地址空间
- 逻辑地址(LA)空间：程序执行的地址空间
- 线性地址(虚拟地址)空间：虚拟内存的地址空间
逻辑地址+段式管理->虚拟地址(线性地址)
	在没有段式内存管理的情况下，逻辑地址和虚拟地址相同
虚拟地址+页式管理->物理地址
	在没有页式内存管理的情况下，逻辑地址和物理地址相同

虚拟内存可以作为外存的缓存，运行的程序直接用虚拟地址，不用关注具体放在物理内存还是外存
## 地址生成过程
（1）OS：建立逻辑地址和物理地址的映射关系表，同时确保每一个程序访问的地址空间是合法的（界限寄存器、基准寄存器：设置逻辑地址空间基准、界限），不能产生交叉干扰的情况
（2）当 CPU 要执行某条指令时，ALU 部件会发出请求指令（发送<font color="#ff0000">逻辑地址</font>）
（3）CPU 中的 MMU 部件会根据逻辑地址和物理地址的映射表，查找 ALU 发送来的逻辑地址对应的物理地址
（4）若没有，则会转移到内存中继续查找物理地址，若找到，则 CPU 的控制器会给主存发出请求，需要某物理地址的内容
（5）主存会将物理地址中的内容，通过总线传递到 CPU
（6）最后 CPU 拿到指令内容，开始执行
![|500](Images/Pasted%20image%2020241117214254.png)
## 连续内存分配
- 静态内存分配：编译时的内存分配
- 动态内存分配：运行时的内存分配
	- 显示分配：要求应用显示释放已分配的块，例如 malloc
	- 隐式分配：编译器/运行时库自动释放未使用的已分配的块
### 最先匹配
![|500](Images/Pasted%20image%2020241117232334.png)
空闲分区列表按**地址顺序**排序
释放分区时，检查是否可与临近的空闲分区合并
优点：简单，在高地址空间有大块的空闲分区
缺点：外部碎片，分配大块时较慢(顺序查找)
### 最佳匹配
![|500](Images/Pasted%20image%2020241117232557.png)
空闲分区列表按**大小**排序
释放分区时，同上
优点：大部分分配的尺寸较小时，效果很好
缺点：外部碎片，释放分区较慢(找临近空闲分区麻烦)，容易产生很多无用的小碎片
### 最差匹配
![|500](Images/Pasted%20image%2020241117233048.png)
空闲分区列表按**由大到小**排序
释放时，进行可能的合并，并调整空闲分区列表顺序
优点：
	中等大小分配较多时，效果最好
	避免出现太多的小碎片
缺点：
	释放分区较慢
	外部碎片
	容易破坏大的空闲分区，因此后续难以分配大的分区
### 碎片整理
- 碎片紧凑：
	- 通过移动分配给进程的内存分区，以合并外部碎片
	- 要求所有的程序可动态重定位
- 分区对换：
	- 通过抢占并回收处于等待状态进程的分区，以增大可用内存空间
## 伙伴系统
整个可分配分区大小为 $2^U$
待分配分区大小为 $2^{U-1}<s\leq 2^U$，将整块分配给应用
由小到大在空闲块中找最小可用块
如果空闲块过大，对可用空闲块进行二等分，直到得到合适可用空闲块
![|800](Images/Pasted%20image%2020241117234528.png)
合并条件：大小相同，低地址空闲块起始地址为 $2^k$
## 非连续内存分配
![|500](Images/Pasted%20image%2020241117235131.png)
### 段式管理地址转换
![|500](Images/Pasted%20image%2020241116154404.png)
### 页式管理地址转换
![|500](Images/Pasted%20image%2020241116154751.png)
控制位：包括修改位、替换位
有效位：表示该页是否已经装入主存
## TLB
TLB 也是 Cache，和 CPU Cache 一样，TLB 也分为数据 TLB 和指令 TLB，也有多种映射方式，也存在多层级
TLB 缓存的是<font color="#ff0000">在 Cache 中的页表项组成的页表</font>
![|500](Images/Pasted%20image%2020241116161919.png)
![|500](Images/Pasted%20image%2020241116162809.png)
Miss1 -> TLB 缺失将产生异常：
- 流水线停止
- 通知 OS
- 查内存页表(也可能 TLB 和页表同步查询)
- 若发生 hit2，将页表项写入 TLB
- 返回到用户程序
- 重新访问
![|500](Images/Pasted%20image%2020241116173444.png)
![|200](Images/Pasted%20image%2020241116171659.png)
![|500](Images/Pasted%20image%2020241116165148.png)
![](Images/Pasted%20image%2020241116172808.png)
![](Images/Pasted%20image%2020241116172722.png)
# IO
I/O 接口(I/O 控制器)的功能：
1. 数据缓冲
   实现主机和外设工作速度的匹配
2. 错误或状态检测
   一类是设备电路故障或异常情况
   另一类是数据传输错误
3. 控制和定时
   接受从控制总线发来的控制信号、时钟信号
4. 数据格式转换
   串-并、并-串等格式转换
![|500](Images/Pasted%20image%2020241116220510.png)
I/O 端口是指 I/O 控制器中 CPU 可访问的寄存器，对 I/O 设备的寻址就是对 I/O 端口的访问
![|500](Images/Pasted%20image%2020241116220742.png)
独立编址：
	优点：不占用内存空间，使用 I/O 指令，译码电路简单
	缺点：只能用专门的 I/O 指令，访问端口的方法少于访问存储器
统一编址：
	优点：可以利用存储器的寻址方式来寻址 I/O 端口
	缺点：I/O 端口占用了存储空间，地址编码长，速度较慢
**数据传送控制方式**
## 程序直接控制
   CPU 直接使用输入/输出指令来控制外部设备   
- CPU 方：查询接口状态(循环等待)->直到外设已经接收到该字符->读字符
- 外设方：往接口数据缓冲中送字符->处理完后，置状态寄存器->等待下一个字符  
**特点**
- 成本低
- 效率低
- 严重占用 CPU 资源
## 程序中断
   外部设备请求，CPU 响应，CPU 与外设并行工作
- 外部设备发起请求->CPU 暂停正在执行的程序进行响应->处理完成后继续执行原来的程序
- 提高 CPU 的效率
- 可以同时管理多个外部设备
**特点**
- 对 I/O 请求慢：每传送一个数据都要等待外设的中断请求，并由额外的中断开销，不能及时响应 I/O 请求
- 数据传送速度慢：数据传送由软件完成(由 CPU 执行相应的中断服务程序来完成)
- 对 CPU 干扰较大
## DMA (直接存储访问)
   专用输入/输出控制器
- 基本思想：在高速外设和主存间之间传送数据，由专门硬件(DMA 接口)控制总线进行传输
- 适用场合：高速设备、成批数据交换，且数据间间隔时间短，一旦启动，数据连续读写
- 主存储器需要支持成组传送
- 采用“请求-响应”方式
	- 每当高速设备准备好数据，就进行一次“DMA 请求”，DMA 控制器接受到 DMA 请求后，申请总线使用权
	- DMA 控制器的总线使用优先级比 CPU 高
- 与中断控制方式结合使用
	- DMA 传送前，“寻道、旋转”等操作结束时，通过“中断”告知 CPU
	- 在 DMA 控制器控制总线进行数据传送时，<font color="#ff0000">CPU 执行其他程序</font>
	- DMA 传送结束时，要通过“DMA 结束中断”告知 CPU
例如：
![|305](Images/Pasted%20image%2020241116235732.png)
**DMA 工作方式**
DMA 接口和 CPU 共享主存，所以可能出现两者争用主存的现象，为协调两者，通常采用如下方式：
- 独占总线方式(成组传送)
  DMA 传输时，CPU 脱离总线，停止访问主存，直到 DMA 传送一块数据结束
	- 优点：控制简单
	- 缺点：CPU 工作受影响
	改进：
	- 在 DMA 接口中引入缓冲器，I/O 设备->缓冲器->主存
	- 采用周期窃取法
- 周期窃取方式(单字传送)
  DMA 传输时，CPU 让出一个总线事务周期，由 DMA 控制总线来访问主存，传送完一个数据后立即释放总线
![|500](Images/Pasted%20image%2020241117001446.png)
适用于 I/O 设备的读写周期大于主存周期
  - 优点：既能及时响应 I/O 请求，又能较好的发挥 CPU 和主存效率
  - 缺点：每次 DMA 访存都要申请占用释放总线，会增加传输开销
![|500](Images/Pasted%20image%2020241117002028.png)
- 交替分时访问法
  每个存储周期分成两个时间片，一个给 CPU，一个给 DMA，这样在每个存储周期内，CPU 和 DMA 都可访问存储器
适用于 CPU 工作周期比主存存取周期更长的情况，不需要总线使用权的申请和释放
![|500](Images/Pasted%20image%2020241117002323.png)
DMA 控制器组成
![|500](Images/Pasted%20image%2020241117003202.png)
![|500](Images/Pasted%20image%2020241117003628.png)
DMA 方式的问题：
- 虚拟地址和实地址
	- DMA 采用实地址：虚拟地址连续，但实地址不连续，需要限制所有 DMA 传送在一个页面进行
	- 采用虚拟地址：DMA 进行虚实地址转换
- Cache 一致性
DMA 特点
- 与设备一对一服务
  多 DMA 控制器同时工作可能发生冲突
- 对 CPU 打扰适中
- 无法适用大量高速设备管理
## 通道
I/O 通道是 OS 中代替 CPU 管理控制外设的独立部件，是一种能执行有限 I/O 指令集合——通道命令的 I/O 处理机
- 一对多的连接关系
- 适应不同速度、不同种类的外部设备、可并行工作
![|500](Images/Pasted%20image%2020241117005136.png)
通道类型：
- 字节多路通道
简单的共享通道，分时处理，面向多台低、中速字符设备
- 选择通道
选择一台外设独占整个通道，以成组传送方式传送数据块，效率高，适合快速设备
- 数组多路通道
上两种方式的结合，效率高，控制复杂
## 外围处理机
输入输出处理机方式是通道方式的进一步发展，有两种输入输出处理机系统结构
1. 通道型处理机(IOP)
   与通道方式一样，也通过执行通道程序对外设进行控制，能和 CPU 并行工作
   区别：IOP 功能更强，有专用指令系统；通道方式下，通道程序存于和 CPU 公用的主存中，而 IOP 有单独的存储器，且可访问系统内存
2. 外围处理机(PPU)
   - 在大型计算机系统中，选用通用计算机担任 PPU
   - 独立完成输入/输出功能
   - 通过通道方式和主机进行交互
# 总线
## 相关概念
总线：多个部件之间进行数据传送的共享通道
总线主设备：有能力控制总线，发起总线事物
总线从设备：响应主设备请求
总线通信协议：定义总线传输中的事件顺序和时序要求
异步总线传输：控制信号(请求，应答)作为总控信号
同步总线传输：使用共同的时钟信号

性能指标：
总线带宽=总线宽度 \* 总线时钟频率 / 完成一次数据传送所用的时钟周期数

![](Images/Pasted%20image%2020241117154134.png)
<font color="#ff0000">总线事务</font>包含两个部分：
- 发起命令（和地址）
- 传输数据
主设备是总线事务的发起者：
- 发出命令（和地址）
从设备是总线事务的响应者：
- 若主设备发出的是读命令，则将数据发送到主设备
- 否则，接收主设备发来的写入数据

**单总线计算机：主板总线**
![|725](Images/Pasted%20image%2020241117151856.png)
优点：简单、成本低
缺点：速度慢，总线将成为系统瓶颈
**双总线系统**
![](Images/Pasted%20image%2020241117152034.png)
- 输入/输出总线通过适配器和处理器-主存总线相连
	- 处理器-主存总线：主要用于处理器和主存储器之间的通信
	- 输入/输出总线：为输入/输出设备提供信息
**三总线系统**
![](Images/Pasted%20image%2020241117152246.png)
主板总线连接到处理器-主存总线
- I/O 总线连接到主板总线
- 处理器-主存总线：主要用于处理器和主存之间数据交换
优点：大大减少处理器-主存总线负载

总线的一般组成：
- 控制线：
	- 标记总线事务的开始和结束
	- 指明数据线上传输信息的类型
- 数据线：在源设备和目标设备间传送信息
	- 数据和地址
	- 复杂的命令
- 地址线：给出源数据或目的数据所在的主存单元或 I/O 模块地址
	- 单向，总是由 CPU 将地址信息送到地址线，随后传送给 CPU 要访问的主存储器或 I/O
有些总线没有单独的地址线，地址信息通过数据线来传送，称为数据线和地址线复用
## 总线仲裁
仲裁：获得总线使用权
### 集中仲裁
菊链仲裁：所有设备共用一个总线请求信号
![](Images/Pasted%20image%2020241117155105.png)
优点：简单
缺点：
- 无法保证公平性
	- 低优先级设备可能得不到总线使用权
- 总线授权信号的逐级传递限制了申请总线的速度

集中平行仲裁：通过集中的仲裁器进行
![|500](Images/Pasted%20image%2020241117160747.png)
### 分布仲裁
通过自我选择进行分布式仲裁：
  - 每个要使用总线的设备将自己的<font color="#ff0000">标识</font>放在总线上
![](Images/Pasted%20image%2020241117161205.png)
碰撞检测：
  - 以太网
## 总线定时方式
同步总线：
- 控制线中包含有一根时钟信号线
- 传输协议根据时钟信号制定：
	例如：主设备提出总线请求后 5 个时钟周期，获得能否使用总线的信号
- 优点：逻辑简单、高速
- 缺点：
	- 总线上所有设备必须按时钟频率工作
	- 为防止时钟信号扭曲，高速工作时，总线距离必须足够短
![|500](Images/Pasted%20image%2020241117164906.png)
异步总线：
- 不使用统一的时钟
- 可适应设备的不同速度
- 不用担心时钟信号扭曲，距离可较长
- 使用握手协议
![|500](Images/Pasted%20image%2020241117164658.png)
7 次握手，全互锁
## 增加总线带宽
采用成组传送方式
- 一个总线事务传送多个数据
- 每次只需要在开始的时候传送一个地址
- 直到数据传送完毕才释放总线
- 代价
	- 复杂度提高
	- 延长后续总线请求的等待时间
多主设备总线提高事务数量
- 仲裁重叠
	- 在当前事务时，为下一总线事务进行仲裁
- 总线占用
	- 在没有其他主设备请求总线的情况下，某主设备一直占用总线，完成多个总线事务
- 地址、数据传送重叠
